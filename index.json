[
{
	"uri": "/jpa-programming/1/page-1-1/",
	"title": "1. JPA 소개",
	"tags": [],
	"description": "",
	"content": " 1. JPA 소개 1.1 SQL을 직접 다룰 때 발생하는 문제점  코드의 반복 작성 : SQL 과 JDBC API 객체연결 코드를 반복 작성해야한다. 객체와 데이터 접근객체 (DAO) 의 진정한 의미의 계층 분할이 어렵다. 엔티티를 신뢰할 수 없다. SQL 에 의존적인 개발을 피하기 어렵다.  1.2 패러다임의 불일치  관계형 데이터 베이스는 데이터 중심으로 구조화. 집합적인 사고를 요구. 객체지향의 추상화, 상속, 다형성 같은 개념이 없다. 객체와 관계형 데이터베이스는 지향하는 목적이 서로 다르며 기능과 표현방법도 다르다. 이것을 객체와 관계형 데이터베이스의 패러다임 불일치 문제라 한다.  패러다임 불일치 문제들 1) 상속  객체에는 상속이라는 기능이 존재하나 테이블은 상속이라는 기능이 없다.  2) 연관관계  객체 : 참조에 접근하여 연관된 객체를 조회한다. 테이블 : 외래키와 조인을 사용하여 연관된 테이블을 조회한다.  3) 객체 그래프 탐색  SQL 을 직접 다루면 처음 실행하는 SQL 에 따라 객체 그래프를 어디까지 탐색할 수 있는지 정해진다. JPA 는 연관된 객체를 사용하는 시점에 적절한 SELECT SQL 을 실행한다. (지연로딩) JPA 는 지연 로딩을 투명(transparent) 하게 처리한다.  4) 비교  동일성 비교(idnetity) 는 == 비교이며, 객체 인스턴스의 참조 값을 비교한다. 동등성 비교(equals) 메서드를 사용하여 객체 내부의 값을 비교한다. JPA 는 같은 트랜잭션 일때 같은 객체가 조회되는 것을 보장한다.  정리  객체 모델과 관계형 데이터베이스 모델은 지향하는 패러다임이 서로 다르다. JPA 는 이러한 패러다임의 불일치 문제를 해결해주고 정교한 객체 모델링을 유지하게 도와준다  1.3 JPA 란 무엇인가. JPA (Java Persistence API) 는 자바 진영의 ORM 기술 표준이다. \u0026lt;그림\u0026gt;\nORM (Object-Relationship Mapping) 은 객체와 관계형 데이터베이스를 매핑한다는 뜻이다.\n 단순히 CRUD 를 제공하는 것 뿐만아니라 ORM 프레임워크는 객체와 테이블을 매핑해서 패러다임의 불일치 문제를 개발자 대신 해결해준다.  JPA 소개 \u0026lt;그림\u0026gt; + JPA 는 자바 ORM 기술에 대한 API 표준 명세이다. (쉽게 말하면, 인터페이스를 모아 둔 것) + JPA 2.1 을 구현한 구현체로는 Hibernate, EclipseLink, DataNucleus 이며 이중 Hibernate 가 가장 대중적이다.\nJPA 를 사용해야 하는 이유  생산성 SQL 을 작성하고 JDBC API 를 사용하는 지루하고 반복적인 CRUD SQL 을 개발자가 직접 작성하지 않아도 된다. 유지보수 필드 추가나 수정 삭제 시에도 개발자가 작성해야 했던 SQL 과 JDBC API 코드를 JPA 가 대신 처리함으로 유지보수 해야하는 코드 수가 줄어든다. 객체 지향 모델의 장점들을 활용하여 유연하고 유지보수하기 좋은 도메인 모델을 설계할 수 있다.\n 패러다임의 불일치 해결\n JPA 는 객체와 관계형 모델 간 패러다임의 불일치 (상속, 연관관계, 객체 그래프 탐색, 비교) 문제를 해결\n 성능\n 같은 트랙잭션 안에서 같은 객체 (같은 테이블)\n 데이터 접근 추상화와 벤더 독립성\n 관계형 데이터베이스는 같은 기능도 벤더마다 사용법이 다른 경우가 존재한다. JPA 는 애플리케이션과 데이터 베이스 사이에 추상화된 데이터 접근 계층을 제공하여, 특정 DBMS 에 종속되지 않도록 한다.\n 표준\n JPA 는 자바 진영의 ORM 기술 표준으로, 표준을 사용하면 다른 구현 기술로 손쉽게 변경할 수 있다.\n  "
},
{
	"uri": "/fluent-python/2/page-2-1/",
	"title": "2. 시퀀스",
	"tags": [],
	"description": "",
	"content": " 2. Sequence 시퀀스 (Sequence) 란 데이터에 순번을 붙여 나열한 데이터들의 집합을 의미한다. 값이 연속적으로 이어져 있는 자료형을 시퀀스 자료형 이라고 한다. 배열처럼 특정 위치의 데이터를 가리킬 수 있다는 특징이 있다.\n2.1 내장 시퀀스 개요 2.1.1 컨테이너 시퀀스와 균일 시퀀스 컨테이너 시퀀스 (container sequence)  객체에 대한 참조를 담고 있다. 객체에 대한 참조를 담고 있으므로 서로 다른 자료형의 항목을 담을 수 있다. list, tuple, collections.deque 형  균일 시퀀스 (flat sequence)  객체에 대한 참조 대신 메모리 공간에 각 항목의 값을 직접 담는다. 문자, 바이트, 숫자 기본 자료형만 저장 할 수 있다. str, bytes, bytearray, memoryview, array.array 형  2.1.2 가변 시퀀스와 불변 시퀀스 가변 시퀀스 (mutable Sequence)  값을 변경 할 수 있으며, 요소를 교체하거나 삭제가 가능하다. list, bytearray, array, array.array, collections.deque, memoryview 형  불변 시퀀스  불변 시퀀스는 생성하거나 destroy 할 수 있지만 요소의 시퀀스 값은 변경 할 수 없다. tuple, str, bytes 형  2.2 지능형 리스트와 제네레이터 표현식 Comprehension 파이썬의 Comprehension 은 시퀀스로부터 다른 형태의 시퀀스로 구성할 수 있는 방법 중 하나 이다. 시퀀스를 간단히 생성할 수 있으며, 가독성이 좋고 때로는 실행 속도가 빠른 코드를 작성 할 수 있다.\n파이썬에는 다음과 같이 크게 네 가지 종류의 Comprehension 이 있다.\n List Comprehension (LC) Set Comprehension (SC) Dict Comprehension (DC) Generator Expression (GE)  2.2.1 지능형 리스트 (List Comprehension) 와 가독성 지능형 리스트 구조  입력 시퀀스 입력 시퀀스를 나타내는 변수 선택적인 조건 표현식 선택적인 조건을 만족하는 입력시퀀스를 출력리스트 요소를 생성하는 출력 표현식  문자열에서 유니코드 코드 포인트 리스트 만들기 (for 문을 사용) \u0026gt;\u0026gt;\u0026gt; symbols = \u0026#39;$¢£¥€₸\u0026#39; \u0026gt;\u0026gt;\u0026gt; codes = [] \u0026gt;\u0026gt;\u0026gt; for symbol in symbols: ... codes.append(ord(symbol)) ... \u0026gt;\u0026gt;\u0026gt; codes [36, 162, 163, 165, 8364, 8376] \u0026gt;\u0026gt;\u0026gt; 문자열에서 유니코드 코드 포인트 리스트 만들기 (List Comprehension) \u0026gt;\u0026gt;\u0026gt; symbols = \u0026#39;$¢£¥€₸\u0026#39; \u0026gt;\u0026gt;\u0026gt; codes = [ord(symbol) for symbol in symbols] \u0026gt;\u0026gt;\u0026gt; codes [36, 162, 163, 165, 8364, 8376] \u0026gt;\u0026gt;\u0026gt;   지능형 리스트는 항목을 필터링 및 변환 함으로써 시퀀스나 기타 반복 가능한 자료형을 만든다. 생성된 리스트를 사용하지 않을 거라면 지능형 리스트 구문을 사용하지 않아야 한다. 지능형 리스트의 구문이 두 줄 이상 넘어가는 경우 코드를 분할하거나 for 문을 이용하여 작성하는 것이 더 좋다.  파이썬에서는 [], {}, () 안에서의 개행이 무시된다.  2.2.2 지능형 리스트와 map() / filter() 비교 지능형 리스트와 맵/필터 구성으로 만든 동일 리스트 # 지능형 리스트로 구성한 리스트 \u0026gt;\u0026gt;\u0026gt; symbols = \u0026#39;$¢£¥€₸\u0026#39; \u0026gt;\u0026gt;\u0026gt; beyond_ascii = [ord(s) for s in symbols if ord(s) \u0026gt; 127] \u0026gt;\u0026gt;\u0026gt; beyond_ascii [162, 163, 165, 8364, 8376] # 맵/필터 함수 구성으로 만든 리스트 \u0026gt;\u0026gt;\u0026gt; beyond_ascii = list(filter(lambda c: c \u0026gt; 127, map(ord, symbols))) \u0026gt;\u0026gt;\u0026gt; beyond_ascii [162, 163, 165, 8364, 8376]  지능형 리스트는 추가적인 lambda 표현식이 필요 없어서 내장 함수인 map() 이나 filter() 를 사용하는 것보다 가독성도 좋고 의도도 명확하다.  2.2.3 데카르트 곱  지능형 리스트는 두 개 이상 반복 가능한 자료혀의 데카르트 곱을 나타내는 일련의 리스트를 만들 수 있다.  \u0026gt;\u0026gt;\u0026gt; colors = [\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;] \u0026gt;\u0026gt;\u0026gt; sizes = [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;] \u0026gt;\u0026gt;\u0026gt; tshirts = [(colors, sizes) for color in colors ... for size in sizes] \u0026gt;\u0026gt;\u0026gt; tshirts [([\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;], [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;]), ([\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;], [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;]), ([\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;], [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;]), ([\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;], [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;]), ([\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;], [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;]), ([\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;], [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;])] \u0026gt;\u0026gt;\u0026gt;  2.2.4 제네레이터 표현식 제너레이터  generator 는 시퀀스형을 iterator 형태로 구성해주는 ( for-each Loop 형태와 같이 시퀀스의 항목을 순차적으로 접근가능한) 함수이다. 값을 반환하고 싶을 때는 yield 구문을 사용하며, next() 메서드를 통하여 순차적으로 시퀀스 항목에 접근이 가능하다.  제너레이터 표현식  지능형 리스트와 동일한 구문을 사용하지만, 대괄호 대신 괄호를 사용하여 제너레이터를 간결하게 작성 가능하다. 반복자 프로토콜을 사용하여 항목을 하나씩 생성함으로 지능형 리스트 보다는 메모리를 적게 사용한다.  지능형 리스트와 제너레이터 표현식 \u0026gt;\u0026gt;\u0026gt; my_list = [1, 3, 6, 10] # 지능형 리스트  \u0026gt;\u0026gt;\u0026gt; [x**2 for x in my_list] [1, 9, 36, 100] # 제너레이터 표현식 \u0026gt;\u0026gt;\u0026gt; (x**2 for x in my_list) \u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x7fa44a703c78\u0026gt; 제너레이터 표현식 간단 예제 \u0026gt;\u0026gt;\u0026gt; my_list [1, 3, 6, 10] \u0026gt;\u0026gt;\u0026gt; result = (x**2 for x in my_list) # next 함수를 통하여 다음 항목에 접근 할 수 있다. \u0026gt;\u0026gt;\u0026gt; print(next(result)) 1 \u0026gt;\u0026gt;\u0026gt; print(next(result)) 9 \u0026gt;\u0026gt;\u0026gt; print(next(result)) 36 \u0026gt;\u0026gt;\u0026gt; print(next(result)) 100 제너레이터 표현식은 함수 안에서 사용 가능하며, 이런경우 괄호를 생략 할 수 있다. \u0026gt;\u0026gt;\u0026gt; sum(x**2 for x in my_list) 146 \u0026gt;\u0026gt;\u0026gt; max(x**2 for x in my_list) 100 2.3 튜플은 단순한 불변 리스트가 아니다.  튜플은 값의 집합이며 괄호를 사용하여 선언한다. 리스트가 지원하는 대부분의 연산을 튜플도 지원하며 리스트와의 차이점은 항목을 재할당 하는 것이 불가능 하다. (immutable)  2.3.1 레코드로서의 튜플  튜플을 필드의 집합으로 사용하는 경우 항목 수가 고정되어 있고 항목의 순서도 중요하다.  2.3.2 튜플 언패킹  튜플 언패킹은 병렬할당(parallel assignment) 을 할 때 가장 눈에 띈다.  패킹 (packing) 과 언패킹 (unpacking) # PACKS values \u0026gt;\u0026gt;\u0026gt; person = (\u0026#34;Riley\u0026#34;, \u0026#34;developer\u0026#34;, \u0026#34;Seoul\u0026#34;) # UNPACKING values \u0026gt;\u0026gt;\u0026gt; (name, job, address) = person \u0026gt;\u0026gt;\u0026gt; print(name) Riley \u0026gt;\u0026gt;\u0026gt; print(job) developer \u0026gt;\u0026gt;\u0026gt; print(address) Seoul \u0026gt;\u0026gt;\u0026gt;  대입문에서는 튜플의 괄호를 생략할 수 있다. # 패킹 \u0026gt;\u0026gt;\u0026gt; numbers = 1, 2, 3, 4, 5 \u0026gt;\u0026gt;\u0026gt; numbers (1, 2, 3, 4, 5) # 언패킹 \u0026gt;\u0026gt;\u0026gt; a, b, c, d, e = numbers \u0026gt;\u0026gt;\u0026gt; a 1 \u0026gt;\u0026gt;\u0026gt;  대입문에서 변수의 개수와 튜플의 값 개수는 같아야한다. \u0026gt;\u0026gt;\u0026gt; name, job = person Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ValueError: too many values to unpack (expected 2) \u0026gt;\u0026gt;\u0026gt;  패킹과 언패킹을 하나의 명령문으로 결합하여 복합 할당 할 수 있다. \u0026gt;\u0026gt;\u0026gt; ( s1 , s2 , s3 , s4 ) = ( \u0026#39;foo\u0026#39; , \u0026#39;bar\u0026#39; , \u0026#39;baz\u0026#39; , \u0026#39;qux\u0026#39; )  튜플 언패킹을 이용하면 임시 변수를 사용하지 않고도 두 변수의 값을 교환 할 수 있다. \u0026gt;\u0026gt;\u0026gt; a, b = 1, 2 \u0026gt;\u0026gt;\u0026gt; a, b = b, a \u0026gt;\u0026gt;\u0026gt; a 2 \u0026gt;\u0026gt;\u0026gt; b 1 튜플 언패킹시 _ 를 사용하여 값을 무시 할 수 있다. # 언패킹시 특정 값 무시 \u0026gt;\u0026gt;\u0026gt; x, _, y = (1,2,3) \u0026gt;\u0026gt;\u0026gt; x 1 \u0026gt;\u0026gt;\u0026gt; y 3 임의의 갯수 데이터 전달 받기  매개 변수 목록을 정의 할 때 시퀀스 패킹 매개변수로 사용할 변수 이름 앞에 * 기호를 붙인다.  \u0026gt;\u0026gt;\u0026gt; a, b, *rest = range(5) \u0026gt;\u0026gt;\u0026gt; a, b, rest (0, 1, [2, 3, 4]) \u0026gt;\u0026gt;\u0026gt; a, b, *rest = range(3) \u0026gt;\u0026gt;\u0026gt; a, b, rest (0, 1, [2]) \u0026gt;\u0026gt;\u0026gt; a, b, *rest = range(2) \u0026gt;\u0026gt;\u0026gt; a, b, rest (0, 1, []) \u0026gt;\u0026gt;\u0026gt;  2.3.3 내포된 튜플 언패킹  튜플은 (a, b, (c,d)) 처럼 다른 튜플을 내포 할 수 있다.  2.3.4 명명된 튜플 (namedtuple)  파이썬의 collections.namedtuple() 함수에는 dictionaries 와 같은 유형을 지원한다. dictionary 와 마찬가지로 특정 값으로 된 키를 포함한다.   색인에 의한 접근 : namedtuple() 의 속성 값은 순서가 매겨지며 색인(index) 에 의해 접근할 수 없는 dictionary 와는 달리 색인(index) 를 사용하여 접근 할 수 있다.\n 키이름 으로 접근 : dictionary 와 마찬가지로 키 이름으로 값에 액세스 할 수 있다.\n getattr() 을 사용 : 키 값을 인수로 제공하여 값에 액세스 하는 방법\n  \u0026gt;\u0026gt;\u0026gt; Student = collections.namedtuple(\u0026#39;Student\u0026#39;,[\u0026#39;name\u0026#39;,\u0026#39;age\u0026#39;,\u0026#39;DOB\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; S = Student (\u0026#39;Nandini\u0026#39;, \u0026#39;19\u0026#39;, \u0026#39;2541997\u0026#39;) # Access using index \u0026gt;\u0026gt;\u0026gt; print (S[1]) 19 # Access using name \u0026gt;\u0026gt;\u0026gt; print (S.name) Nandini # Access using getattr() \u0026gt;\u0026gt;\u0026gt; print (getattr(S, \u0026#39;DOB\u0026#39;)) 2541997 2.3.5 불변 리스트로서의 튜플  튜플은 항목을 추가하거나 삭제하는 기능 및 reserved() 메서드를 제외하고 리스트가 제공하는 메서드는 모두 지원한다. 읽을거리 - http://radar.oreilly.com/2014/10/python-tuples-immutable-but-potentially-changing.html  2.4 슬라이싱  파이썬에서 제공하는 list, tuple, str 그리고 모든 시퀀스형은 슬라이싱(slicing) 연산을 지원한다. slice() 는 범위 (start, stop, step) 으로 지정된 범위의 객체들을 가져오는 방법을 의미한다. 슬라이싱을 하면 새로운 객체를 생성하게 된다.  2.4.1 슬라이스와 범위 지정시에 마지막 항목이 포함되지 않는 이유  range(3) 또는 my_list[:3] 처럼 중단점만 이용해서 슬라이스 범위를 지정할때 길이 계산이 쉽다. 시작점과 중단점을 모두 지정할 때도 길이 계산이 쉽다. 단지 중단점에서 시작점을 빼면 된다. 중단점을 기준으로 겹침 없이 시퀀스를 분할하기가 쉽다.  2.4.2 슬라이스 객체  s[a:b:c] 는 c 보폭만큼씩 항목을 건너 뛰게 만든다. 슬라이스는 아래와 같이 두개의 구문이 있다.  slice(stop) slice(start, stop, step)  start - 슬라이스를 시작할 인덱스 (Optional) stop - 슬라이스 중단점 + 1 step- 각 덱스 사이의 증가량 (Optional)  \u0026gt;\u0026gt;\u0026gt; s = \u0026#39;bicycle\u0026#39; \u0026gt;\u0026gt;\u0026gt; s[::3] \u0026#39;bye\u0026#39; \u0026gt;\u0026gt;\u0026gt; s[::-1] \u0026#39;elcycib\u0026#39; \u0026gt;\u0026gt;\u0026gt; s[::-2] \u0026#39;eccb\u0026#39;  슬라이스 객체는 슬라이스에 이름을 붙일 수 있다.  https://mingrammer.com/introduce-comprehension-of-python/ https://python-3-patterns-idioms-test.readthedocs.io/en/latest/Comprehensions.html#list-comprehensions\n"
},
{
	"uri": "/notes/",
	"title": "Note",
	"tags": [],
	"description": "",
	"content": " Notes  공부하고 있는 책이나 강의 내용을 정리하는 공간  정리중  Elasticsearch Mastering Spring Framework 5.0 자바 ORM 표준 JPA 프로그램  "
},
{
	"uri": "/elasticsearch/1/",
	"title": "1 Week",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/elasticsearch/3/page-3-1/",
	"title": "3.1 Configuring Elasticsearch",
	"tags": [],
	"description": "",
	"content": " Configuring Elasticsearch Elasticsearch 는 정적으로 설정을 구성할 수 있을 뿐만 아니라 클러스터 운영중에도 클러스터 세팅 업데이트 API 를 통하여 동적인 설정 구성이 가능합니다.\nStatic settings Elasticsearch는 노드별로 설정파일을 구성할 수 있습니다. Elasticsearch 에는 세 개의 구성 파일이 있습니다. 설정 파일들의 위치는 아카이브 배포판 설치시에는 $ES_HOME/config, 패키지 배포시에는 (RPM 설치 등) /etc/elasticsearch 에 위치해 있습니다.\n elasticsearch.yml : Elasticsearch 의 핵심 설정 jvm.options : JVM 옵션 설정 ( heapsize 설정 ) log4j2.properties : Elasticsearch 의 logging 설정  Dynamic settings 클러스터에 REST API 로 호출하여 클러스터를 운영중에도 구성 설정을 변경 할 수 있습니다.\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html#settings\n"
},
{
	"uri": "/spring5.0/6/",
	"title": "6. Extending Microservices",
	"tags": [],
	"description": "",
	"content": " 6. Extending Microservices 1. 예제 프로젝트 생성  Spring Initializr 로 프로젝트 생성하기 https://start.spring.io/   "
},
{
	"uri": "/jpa-programming/1/page-1-2/",
	"title": "2. JPA 시작",
	"tags": [],
	"description": "",
	"content": " 2. JPA 시작 "
},
{
	"uri": "/elasticsearch/3/page-3-2/",
	"title": "elasticsearch.yml",
	"tags": [],
	"description": "",
	"content": " elasticsearch.yml elasticsearch.yml 은 데이터 파일 위치, 로그파일 위치 등 클러스터의 핵심적인 설정을 할 수 있는 구성 파일입니다. 파일 포맷은 YAML 로 되어 있습니다.\n# path.data : 데이터파일의 위치를 설정 # path.logs : ES 의 로그 파일이 저장될 위치를 설정path:data:/var/lib/elasticsearchlogs:/var/log/elasticsearch# 클러스터를 고유하게 식별할 수 있는 이름 설정cluster:name:es-cluster# 노드를 고유하게 식별할 수 있는 이름설정# 보통 호스트명 기준으로 설정하는 것이 운영에 용이 nodename:es-master01 path.data path.data 는 Index 의 데이터를 저장할 경로를 지정할 수 있습니다. 경로는 하나 혹은 여러개로도 지정이 가능합니다.\n# ex) single pathpath:data:/data1# ex ) multi pathpath:data:/data1,/data2 path.logs path.logs 는 Elasticsearch 의 로그를 저장할 경로를 지정할 수 있습니다. 어플리케이션 운영 로그, Elasticsearch Deprecated 로그, Indexing, Searching Slow 로그 등이 저장됩니다.\nDiscovery 설정 discovery 모듈은 클러스터 내의 노드를 발견하고 마스터 노드를 찾아내는 방식을 의미합니다. Elasticsearch 는 P2P 기반의 시스템이며, 노드간 통신은 ping 을 기반으로 동작합니다. ( 노드간 작업의 위임 broadcast ) 이 discovery 모듈에는 Zen discovery, EC2 discovery, GCE(Google Computer Engine) discovery 등을 지원합니다.  Elasticsearch 는 노드간 클러스터링 및 마스터 선출을 위해 Zen Discovery 라는 사용자 정의 검색 구현을 설정할 수 있습니다.\ndiscovery.zen.ping.unicast.hosts 동일한 클러스터 명을 전제로 설정된 호스트들 가운데 Master 를 선출 할 수 있습니다. 이 설정에는 다른 노드 들에게 마스터 노드의 목록을 제공 할 수 있습니다.\n# ex) master node host discovery.zen.ping.unicast.hosts:[\u0026#34;1.1.1.1:9300\u0026#34;,\u0026#34;1.1.1.2:9300\u0026#34;,\u0026#34;2.2.2.1:9300\u0026#34;,] discovery.zen.minimum_master_nodes 적합한 마스터 노드의 최소 갯수를 설정 할 수 있습니다. 이 설정을 통려하여 네트워크 장애등으로 인하여 동일 클러스트 내에 마스터들이 최소 갯수만큼 내려가면 데이터 무결성을 위해 클러스터가 중지처리 됩니다. ( Split Brain 피하기 위함.)\n마스터 노드의 최소 갯수 \n (master_eligible_nodes / 2) + 1\n Network 설정 network.host 노드가 응답 할 수 있는 IP 또는 호스트를 설정합니다. 기본적으로 Elasticsearch 는 루프백 주소에만 바인드 합니다.(ex 127.0.0.1 ) 이는 단일 노드에서는 문제 없으나 여러 노드가 운용되는 클러스트 구성을 위해서는 비 루프백 주소를 바인드 해 주어야 합니다.\nnetwork.bind_host notework.host 설정에서 외부의 데이터 호출을 받는 부분만 분리 할 수 있습니다. # ex) network.bind_hostnetwork.bind_host:0.0.0.0\nnetwork.publish_host 클러스트 내 다른 노드들과 통신 하는 부분만 분리 할 수 있습니다. # ex) network.bind_hostnetwork.publish_host:10.190.5.5\nhttp.port HTTP 프로토콜을 통해 Elasticsearch 의 API 를 전달할 때 사용할 포트를 지정할 수 있습니다. # ex) http.porthttp.port:9200\ntransport.tcp.port 클러스터 내에 노드들이 서로 통신할 때 사용할 포트를 설정합니다. 노드들은 서로의 용량과 샤드들의 상태를 알아야 하기 때문에 TCP 통신을 합니다.\n# ex) transport.tcp.porttransport.tcp.port:9300 Node Role 설정 Node Role 로는 master-eligible, data, ingest node, coordinate node 가 있습니다. elasticsearch.yml 설정을 통하여 각 노드의 역할을 부여할 수 있습니다.\nMaster-eligible Node 마스터 노드로서의 역할을 할 수 있는 노드를 의미합니다.\n# ex) master node rolenode.master:truenode.data:falsenode.ingest:false Data Node 데이터를 저장되는 역할을 할 수 있는 노드를 의미합니다. # ex) data node rolemaster.node:falsenode.data:truenode.ingest:false\nInjest Node 문서가 인덱싱 되기 전에 파이프라인을 통해 사전처리를 할 수 있는 역할이 부여된 노드입니다. 기본값을 true 이며 보통 client node 를 세팅할 때 사용합니다.\n# ex) ingest node rolemaster.node:falsenode.data:falsenode.ingest:true Coordinate Node 클라이언트의 요청을 받고 라우팅 및 분산처리만 할 수 있는 역할이 부여된 노드입니다.\n# ex) Coordinate node rolemaster.node:falsenode.data:falsenode.ingest:false 그외 설정 http.cors.enabled: true 웹 브라우저나 Elasticsearch 에서 접근할 수 있도록 하는 설정합니다. Head / HQ 플러그인 사용시 설정할 수 있습니다.\nhttp.cors.allow-origin: \u0026ldquo;*\u0026rdquo; 웹 브라우저로 접근할 수 있는 IP ACL 설정입니다.\nhttps://www.elastic.co/guide/en/elasticsearch/reference/6.4/discovery-settings.html#minimum_master_nodes https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#node-ingest-node\n"
},
{
	"uri": "/elasticsearch/2/",
	"title": "2 Week",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/elasticsearch/1/page-1-1/",
	"title": "1.1 Basic Concepts",
	"tags": [],
	"description": "Elasticsearch 개념 및 용어 정리 - Document, Index, Type, Cluster, Node",
	"content": " 1.1 Basic Concepts - 1 Document  도큐먼트는 JSON (Javascript Object Notation) 형태의 Elasticsearch 의 기본 저장단위 이다. 관계형 데이터 베이스의 Row 와 비슷한 개념으로 볼 수 있다. 도큐먼트는 데이터에 적재될 때 Document ID 를 갖는다. Document ID 는 지정하지 않으면 랜덤하게 생성 되며, 사용자가 정의한 값으로도 생성 가능하다. Document ID 는 데이터를 찾아가는 Metadata 로 볼 수 있다.  Index  Index 는 비슷한 형질을 가지는 도큐먼트 간의 집합이다. 관계형 데이터 베이스의 Database 와 비슷한 개념으로 볼 수 있다. 여러 도큐멘트들이 하나의 인덱스에 적재된다. 인덱스 이름은 문서에 대한 인덱싱/검색/갱신/삭제 등을 수행할 때 참조값으로 사용된다. 인덱스는 사전에 정의되어야 할 데이터 타입이나, 특정한 구조가 필요하지 않다면 최초 데이터가 인입될 때 생성 된다. ex) 고객정보, 제품카탈로그, 주문정보 등\u0026hellip;  Type  관계형 데이터 베이스의 Table 과 비슷한 개념으로 볼 수 있다. 타입은 인덱스의 파티션으로 사용 된다. 하나의 인덱스에 도큐먼트를 저장할때 타입을 분리해서 인덱싱이 가능하다.  ES 6.0.0 버전 부터는 Multi Type 을 지정이 Deprecated 되었으며, 하나의 인덱스에는 단일 타입으로만 지정하도록 권고하고 있다.  Cluster  Elasticsearch 는 클러스터로 구성되어 있다. 클러스는 전체 데이터 (모든 노드) 간 통합 인덱싱 및 검색이 가능한 1개 이상의 노드(서버) 의 집합이다. 사용자는 이 클러스터를 통해 데이터를 저장하고 검색 요청을 할 수 있다. 클러스터는 고유의 cluster_name 과 cluster_uuid 를 갖는다. 클러스터 이름은 따로 지정하지 않으면 유니크한 이름으로 생성된다.  Node  노드는 클러스터를 구성하는 단일 서버로써, 서로 헬스 체크를 하거나 혹은 데이터를 저장하고 클러스터에 참여하여 인덱싱과 검색 역할을 수행한다. 노드는 각자의 노드 이름을 갖으며 노드가 기동될때 랜덤 UUID 를 갖는다. 노드는 역할에 따라 master node, data node, all node, client node 등으로 구성할 수 있다.  모든 노드는 클러스터의 다른 모든 노드에 대해 알고 있으며, 클라이언트 요청을 해당 노드로 전달할 수 있다.     노드 구분 설명     master node 클러스터를 제어하는 마스터 노드. 구성 노드들의 헬스 체크를 담당한다.   data node 데이터를 저장하고 CRUD, 검색 및 집계와 같은 데이터 관련 작업을 수행한다.   all node master 혹은 data 노드의 구분이 필요 없을 때 두가지 역할을 담당한다. 보통은 확장이 필요 없거나 요청 쿼리가 많지 않고 데이터를 오래 보관해야 하는 경우 구성한다.   client node 쿼리만을 받기 위한 노드이며, 부하가 많거나 요청 쿼리량이 많을 때 부하 분산용으로 구성한다.    [참고]\n Elasticsearch Reference - Basic Concepts  "
},
{
	"uri": "/spring5.0/11/",
	"title": "11. Reactive Programming",
	"tags": [],
	"description": "",
	"content": " 1. Details "
},
{
	"uri": "/spring5.0/11/page-11-1/",
	"title": "11.1 Reactive Programming",
	"tags": [],
	"description": "",
	"content": " 11.1 Reactive Programming 1. 리액티브 시스템 새로운 디바이스 (모바일, 태블릿 등) real-time data 에 대한 수요 증가\n 대량의 프로세스 처리 로드 발생 데이터 볼륨이 기하급수적으로 증가 인프라 유지 보수 비용 증가  1.1 Reactive 시스템 특징  Reactive manifesto : https://www.reactivemanifesto.org/ko  Reative Manifesto 는 다음 네 가지 핵심 원칙에 따라 Reactive System 의 특성을 개략적으로 설명하고 있다.\n 반응성 (Responsive) : 모든 응답은 적시에 빠르고 일관된 대응을 제공하며 신뢰할수 있으며 일관된 서비스 품질을 제공한다.\n 회복력 (Resilient) : 각각의 구성요소 들이 분리되어 있기 때문에 구성요소 중 하나에 문제가 발생하더라도 전체 시스템이 다운되는 것을 방지하고 복구 할 수 있도록 보장한다. 또한 장애의 발생이 예외적인 현상이 아닌 정상적인 기능의 일부로 처리한다.\n 유연성 (Elastic) : 요청을 처리하기 위해 할당된 리소스를 늘리거나 줄임으로써 요청 로드의 변화에 대응할 수 있다. ( auto scale )\n 메시지 기반(Message-driven) : 시스템의 구성요소들이 메세지(또는 이벤트) 를 통해 이루어진다. 여기에서 구성요소들은 컴포넌트, 서비스, 객체, API 무엇이라도 될 수 있으며 과거처럼 메서드 호출이나 RPC 같은 블로킹 방식으로 의사소통 하지 않고, 보내고 잊는(fire-and-forget) 방식으로 메시지를 주고 받으며 소통한다.\n  [출처] http://www.zdnet.co.kr/view/?no=20161010104628 1.2 Reactive Keyworld  A reactive stream should be non-blocking It should be a stream of data It should work asynchronously And it should be able to handle back pressure.  2 Non-Bloking Bloking 블로킹은 요청이 발생하고 작업을 진행하는 동안 프로그램의 진행을 멈추고(block) 완료될 때까지 모든 일을 중단한 상태로 대기해야 하는 것을 블로킹 방식이라고 한다.\nBlocking Java Socket 통신 예제  클라이언트가 접속할 때 까지 accept() 메서드는 항상 블로킹 된다.  Socket clientSocket = serverSocket.accept();String request, response; while ((request = in.readLine()) != null) { response = processRequest(request); out.println(response); if (\u0026#34;Done\u0026#34;.equals(request)) { break; } }  또한 클라이언트가 보낸 스트림이 완료 또는 입력 끝 문자 ( Ctrl + C 입력 시) 를 보낼 때 까지 발생한다. 클라이언트가 많을 수록 스레드 수가 증가하고 서버에 심각한 성능저하 발생 -\u0026gt; 대안으로 스레드 풀을 사용  Non-Blocking 어떤 스레드에서 오류가 발생하거나 멈추었을 때 다른 쓰레드에게 영향을 끼치지 않도록 하는 방법이다. 요청한 작업(스레드) 이 진행 되는 동안 즉시 다음 작업을 처리함으로써 시스템 자원을 더 효율적으로 활욜이 가능하다. 그러나 요청한 작업 이후 후속 작업을 이어서 진행할 수 있도록 별도의 약속(Polling, Callback Function 등) 이 필요하다.\nthis.selector = Selector.open(); ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); // bind server socket channel to port  serverChannel.socket().bind(listenAddress); serverChannel.register(this.selector, SelectionKey.OP_ACCEPT);  accept() 메서드가 블로킹 되지 않고 바로 리턴되기 때문에, 클라이언트가 연결 요청을 보내기 전까지 while 블록 코드가 쉴새 없이 반복되어 CPU가 과도하게 소비되는 문제점이 발생한다. 그래서 넌블로킹은 이벤트 리스너 역할을 하는 셀렉터(Selector) 를 사용한다. 이 Selector 를 넌블로킹 채널에 등록해 놓으면 클라이언트의 연결 요청이 들어오거나 데이터가 도착할 경우 채널은 Selector 에 통보한다. Selector는 통보한 채널들을 선택해 작업 스레드가 accept() 또는 read() 메소드를 실행한다.\nwhile (true) { int readyCount = selector.select(); if (readyCount == 0) { continue; } } 출처 및 참고 사이트  https://homoefficio.github.io/2017/02/19/Blocking-NonBlocking-Synchronous-Asynchronous/ http://palpit.tistory.com/645 https://tech.peoplefund.co.kr/2017/08/02/non-blocking-asynchronous-concurrency.html https://medium.com/coderscorner/tale-of-client-server-and-socket-a6ef54a74763  1.5 Backpressure 비동기식 데이터 스트림 처리에 대한 이슈  너무 큰 데이터 스트림 -\u0026gt; busy waiting 너무 빠른 데이터 스트림 전송 속도 -\u0026gt; out of memory exception  Backpressure 는 안정적으로 처리하기에 너무 큰 데이터 혹은 데이터를 신뢰 있게 처리 할 수 있는 속도로 구독자에게 제공하는 방법이다. Reactive 데이터 스트림의 Push 와 Pull 을 관리하는 Buffer 를 사용하여 구독자는 특정 양의 데이터를 요청하고 소스는 구성된 데이터를 해당 데이터로 유동적으로 Push 와 Pull 을 하는 방식이다.\n출처 및 참고 사이트  https://www.slideshare.net/dnnddane/why-reactivereactive-programming-spring-5 https://www.youtube.com/watch?v=UIrwrW5A2co ReactiveX History : https://ahea.wordpress.com/2017/02/03/reactive-history/\n https://www.slideshare.net/ktoso/reactive-stream-processing-with-akka-streams\n https://www.e4developer.com/2018/04/28/springs-webflux-reactor-parallelism-and-backpressure/\n  "
},
{
	"uri": "/spring5.0/6/page-6-1/",
	"title": "6.1 예외처리",
	"tags": [],
	"description": "스프링부트에서 제공하는 기본 예외처리와 사용자 정의 예외처리에 대해 정리",
	"content": " 6.1 예외처리 1. 스프링 부트의 기본 예외처리  스프링부트의 기본 예외 형식은 throw 된 예외 메세지 와 함께 JSON 형태로 에러를 리턴한다. 브라우저경우 기본 오류 페이지 (Whilelabel Error Page) 를 출력한다.  { \u0026#34;timestamp\u0026#34;: \u0026#34;2018-12-25T05:01:26.483+0000\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Some Exception Occurred\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/users/dummy-service\u0026#34; } 2. 스프링 사용자 정의 예외처리 스프링에서는 오류에 대한 응답을 사용자가 정의하는 여러 옵션을 제공한다.\n2.1 응답 메세지 사용자 정의 하기  주어진 ID 가 가지고 있는 todo 가 발견되지 않았을 때 발생시킬 사용자 정의 TodoNotFoundException 와 메세지 처리를 할 ExceptionResponse 객체를 생성한다.  package com.mastering.spring.springboot.exception; public class TodoNotFoundException extends RuntimeException { public TodoNotFoundException(String msg) { super(msg); } }package com.mastering.spring.springboot.bean; import java.util.Date; public class ExceptionResponse { private Date timestamp = new Date(); private String message; private String details; public ExceptionResponse(String message, String details) { super(); this.message = message; this.details = details; } public Date getTimestamp() { return timestamp; } public void setTimestamp(Date timestamp) { this.timestamp = timestamp; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } public String getDetails() { return details; } public void setDetails(String details) { this.details = details; } }  TodoNotFoundExcption 이 발생하면 ExceptionResponse Bean 을 사용해 응답을 반환할 컨트롤러를 생성한다.  @ControllerAdvice @RestController public class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler { @ExceptionHandler(TodoNotFoundException.class) public final ResponseEntity\u0026lt;ExceptionResponse\u0026gt; todoNotFound(TodoNotFoundException ex) { ExceptionResponse exceptionResponse = new ExceptionResponse(ex.getMessage(), \u0026#34;Any details you would want to add.\u0026#34;); return new ResponseEntity\u0026lt;ExceptionResponse\u0026gt;(exceptionResponse, new HttpHeaders(), HttpStatus.NOT_FOUND); } } 2.2 모든 예외에 사용자 정의 예외처리 정의하기 아래 코드는 사용자 정의 예외 이외에 모든 예외에 대해 사용자 정의 예외 메세지를 응답하도록 설정한다.\n@ExceptionHandler(Exception.class) public ResponseEntity\u0026lt;ExceptionResponse\u0026gt; defaultError(Exception ex) { ExceptionResponse exceptionResponse = new ExceptionResponse(ex.getMessage(), \u0026#34;알수없는 에러...\u0026#34;); return new ResponseEntity\u0026lt;ExceptionResponse\u0026gt;(exceptionResponse, new HttpHeaders(), HttpStatus.INTERNAL_SERVER_ERROR); }  @ControllerAdvice 를 이용하여 @ExceptionHander 를 모든 패키지 및 컨트롤러에서 전역적으로 사용할 수 있도록 정의한다. @ExceptionHandler(TodoNotFoundException.class) 가 특정 에러 유형(클래스) 에 대해 예외처리 하도록 정의한다. 사용자 예외 처리가 되어 있지 않은 다른 예외는 스프링부트의 기본 예외처리 형태를 따른다. @RestController 을 사용하여 클라이언트에게 응답처리를 할 수 있게 한다.  2.3 사용자 정의 에러에 특정 HTTP 응답 상태 지정하기 @ResponseStatus 어노테이션을 사용하여 커스텀 에러에 특정 HTTP 응답 상태를 지정할 수 있다.\n@ResponseStatus(HttpStatus.NOT_FOUND) public class TodoNotFoundException extends RuntimeException { public TodoNotFoundException(String msg) { super(msg); } } 3. HTTP 응답 상태 코드  상세 응답코드 정의 : https://developer.mozilla.org/ko/docs/Web/HTTP/Status     응답 상태 상황     400 - BAD REQUEST 요청본문이 API 스펙을 충족하지 못하여 서버가 요청을 이해할 수 없음을 의미.   401 - UNAUTHORIZED 인증 또는 권한 부여 실패   403 - RESOURCE FORBIDDEN 클라이언트가 컨텐츠에 접근할 권리를 갖고 있지 않음. 401 과 다른 점은 클라이언트가 누구인지 알고 있음.   404 - RESOURCE NOT FOUND 요청한 리소스가 존재하지 않음   405 - METHOD NOT ALLOWED 지원되지 않는 오퍼레이션 (ex : GET 요청한 허용되는 리소스에 POST 요청을 시도)   500 - INTERNAL SERVER ERROR 서버에서 에러가 발생하여, 소비자는 이 문제를 해결 할 수 없음.    4. ResponseStatusException (Spring 5 and Above)  https://www.baeldung.com/exception-handling-for-rest-with-spring  "
},
{
	"uri": "/elasticsearch/",
	"title": "Elasticsearch",
	"tags": [],
	"description": "",
	"content": " Elasticsearch  Elasticsearch 는 Apache Lucene 기반의 Full-Text 검색엔진 이며 분석엔진 이다. 고가용성(High Availability) 의 확장 가능한 오픈 소스이다. HTTP 웹 인터페이스와 스키마에서 자유로운 JSON 문서로 제공된다.  검색 엔진으로서의 Elasticsearch Elasticsearch 는 루씬 기반의 대중적인 엔터프라이즈 검색엔진으로, Apach 2.0 License 에 의거 오픈 소스로 출시 되었다. 또한 대부분의 루씬이 제공하는 기능들을 Eleasticsearch 에서도 제공한다.\nApache Lucene  정보검색(Information Retrieval, IR) 소프트웨어 검색 라이브러리 Apahce Software 재단의 검색엔진 상위 프로젝트 자바 언어로 개발되어 있다. 오픈소스 주요기능  사용자 위치 정보 이용 가능 다국어 검색 지원 자동 완성 지원 미리 보기 지원 철자 수정 기능 지원   분석 엔진으로서의 Elasticsearch Elasticsearch 는 검색엔진으로 단독으로 서비스 하지만, 몇 가지 솔루션을 추가하여 분석엔진으로서도 활용이 가능하다.\n관련솔루션 Kibana  Elasticsearch 에 존재하는 데이터를 실시간으로 분석 및 시각화.  Beats  데이터 수집기. 서버 혹은 단말에 Agent 형태로 Elasticsearch 나 Logstash 로 데이터를 전달  Logstash  직접 로그를 전달하거나 Beats 에서 데이터를 전달받아 파싱 혹은 필터링 하여 Elasticsearch 로 전달  "
},
{
	"uri": "/jpa-programming/1/page-1-3/",
	"title": "3. 영속성 관리",
	"tags": [],
	"description": "",
	"content": " 3. 영속성 관리 JPA 가 제공하는 기능  엔티티와 테이블을 매핑하는 기능 매핑하는 엔티티를 실제 사용하는 기능  3.1 엔티티 매니저 팩토리와 엔티티 매니저 EntityManagerFactory  EntityManagerFactory 는 이름 그대로 EntityManager 를 만드는 공장이다. 공장을 만드는 비용은 상당히 크므로, 한 개만 만들어서 애플리케이션 전체에 공유하도록 설계해야 한다. EntityManagerFactory 는 여러 스레드에서 동시에 접근해도 안전하므로 서로 다른 스레드간 공유해도 된다.  // MET-INF/persistence.xml 의 정보를 바탕으로 생성한다. EntityManagerFactory emf = Persistence.createEntityManagerFactory(\u0026#34;jpabook\u0026#34;); EnitityManager  EntityManager 를 EntityManagerFactory 에서 생성하는 비용은 거의 들지 않는다. EntityManager 의 경우 여러 스레드가 동시에 접근하면 동시성 문제가 발생하므로 스레드간 절대 공유해서는 안된다. 엔티티 매니저는 데이터베이스 연결이 꼭 필요한 시점까지 커넥션을 얻지 않는다. (ex. 트랜잭션을 시작할 때 커넥션을 획득한다.)  EntityManager em = emf.createEntityManager(); 3.2 영속성 컨텍스트  영속성 컨텍스트 (persistence context) 는 엔티티를 영구 저장하는 환경 이다. 영속성 컨텍스트는 엔티티를 조회, 보관 등 관리하는 곳으로 눈에 보이지 않는 논리적인 개념이다. 엔티티 매니저를 생성할 때 하나 만들어지며, 엔티티 매니저를 통해 영속성 컨텍스트에 접근 할 수 있고 영속성 컨텍스트를 관리 할 수 있다.  // 엔티티 매니저를 사용해서 회원 엔티티를 영속성 컨텍스트에 저장한다. em.persist(member);  여러 엔티티 매니저가 같은 영속성 컨텍스트에 접근 할 수도 있다.\n 3.3 엔티티의 생명주기 엔티티의 4가지 상태  비영속(new/transient) : 영속성 컨텍스트와 전혀 관계가 없는 상태 영속(managed) : 영속성 컨텍스트에 저장된 상태 준영속(detached) : 영속성 컨텍스트에 저장되었다가 분리된 상태 삭제(removed) : 삭제된 상태  [그림3.1] 엔티티 생명주기 비영속  비영속 상태는 영속성 컨텍스트나 데이터베이스와는 전혀 관련이 없다.  // 객체를 생성한 상태(비영속)  Member member = new Member(); member.setId(\u0026#34;memberId\u0026#34;); member.setUsername(\u0026#34;홍길동\u0026#34;); 영속  엔티티 매니저를 통해 엔티티를 영속성 컨텍스트에 저장한 상태. 영속성 컨텍스트가 관리하는 엔티티를 영속 상태 라 한다. em.find() 나 JPQL 을 사용해서 조회한 엔티티도 영속성 컨텍스트가 관리하는 영속 상태다.  // 객체를 저장한 상태(영속) em.persist(member); 준영속  영속성 컨텍스트가 관리하던 영속상태의 엔티티를 영속성 컨텍스트가 관리하지 않으면 준영속 상태가 된다. 준영속 상태로 만들려면 em.detach() 나 em.close() 를 호출하여 영속성 컨텍스트를 닫거나 또는 em.clear() 영속성 컨텍스트를 초기화 하는 방법이 할때 준영속 상태가 된다.  // 회원 엔티티를 영속성 컨텍스트에서 분리 (준영속 상태) em.detach(member); 삭제  엔티티를 영속성 컨텍스트와 데이터베이스에서 삭제한다.  // 객체를 삭제한 상태(삭제) em.remove(member); 3.4 영속성 컨텍스트의 특징 1) 영속성 컨텍스트와 식별자 값  영속상태는 식별자 값이 반드시 있어야 한다. 영속성 컨텍스트는 엔티티를 식별자 값(@Id 로 테이블의 기본키와 매핑한 값) 으로 구분한다.  2) 영속성 컨텍스트와 데이터 베이스 저장  JPA 는 보통 트랜잭션을 commit 하는 순간 영속성 컨텍스트에 새로 저장된 엔티티를 데이터 베이스에 반영한다. 이것을 플러시(flush) 라고 한다.  3) 영속성 컨텍스트가 엔티티를 관리하면 다음과 같은 장점이 있다.  1차 캐시 동일성 보장 트랜잭션을 지원하는 쓰기 지연 변경 감지 지연 로딩  3.4.1 엔티티 조회  영속성 컨텍스트는 내부에 캐시를 가지고 있으며 이것을 1차 캐시라고 한다. 영속 상태의 엔티티는 모두 이곳에 저장된다. 영속성 컨텍스트 내부에 Map 이 하나 있는데 키는 @Id 로 매핑한 식별자고 값은 엔티티 인스턴스 이다. 1차 캐시의 키는 식별자 값이며 기본적으로 데이터베이스의 기본키와 매핑되어 있다.  영속성 컨텍스트 1차 캐시 // 엔티티를 생성한 상태 (비영속) Member member = new Member(); member.setId(\u0026#34;member1\u0026#34;); member.setUserName(\u0026#34;회원\u0026#34;); em.persist(member); // 엔티티를 영속  회원 엔티티는 아직 데이터베이스에 저장되지 않았다.\n 1차 캐시에서 조회 Member findMember = em.find(Member.class, \u0026#34;member1\u0026#34;);  em.find() 를 호출하면 우선 1차 캐시에서 식별자 값으로 엔티티를 찾는다.  데이터베이스에서 조회 // 1차 캐시에 없는 member2 인스턴스를 조회 Member findMember2 = em.find(Member.class, \u0026#34;member2\u0026#34;);  만약 em.find() 를 호출했는데 엔티티가 1차 캐시에 없으면 엔티티 매니저는 데이터 베이스를 조회하여 엔티티를 생성한다. 그리고 1차 캐시에 저장한 후 반환한다.   em.find(Member.class, \u0026quot;member2\u0026quot;) 를 실행 member2 가 1차 캐시에 없으므로 데이터베이스에서 조회 조회한 데이터로 member2 엔티티를 생성하여 1차 캐시에 저장 (영속상태) 조회한 엔티티 인스턴스를 반환  영속성 엔티티의 동일성 보장 Member a = em.find(Member.class, \u0026#34;member1\u0026#34;); Member b = em.find(Member.class, \u0026#34;member1\u0026#34;); // 결과값은 true. System.out.println(a == b);   em.find(Member.class, \u0026quot;member1\u0026quot;) 를 반복해서 호출해도 영속성 컨텍스트는 1차 캐시에 있는 같은 엔티티 인스턴스를 반환한다. 영속성 컨텍스트는 성능상 이점과 엔티티의 동일성을 보장한다.  이미지 출처  http://ptgmedia.pearsoncmg.com/images/chap8_9780131587564/elementLinks/08fig01.jpg  "
},
{
	"uri": "/elasticsearch/1/page-1-2/",
	"title": "1.2 Basic Concepts - Shard",
	"tags": [],
	"description": "Elasticsearch 개념과 용어 정리 - Shard, Primary Shard, Repolica Shard",
	"content": " 1.2 Basic Concepts - 2 Shard 란 Shard 란 인덱스의 데이터를 나누는 단위 이다. 인덱스는 무한한 양의 데이터가 저장이 가능하다. 그래서 인덱스 데이터가 단일 노드의 하드웨어의 용량을 초과하여 더이상 데이터를 저장할 수 없거나 혹은 CPU, Memory 의 자원 초과로 인덱싱이나 검색의 성능 저하를 발생시킬 수 있다. 이러한 문제를 해결하기 위하여 인덱스를 수 많은 조각으로 나누어 관리한다.\n샤딩을 함으로써  콘텐츠 볼륨의 수평(Horizontal) 분할 및 확장이 가능하다. (관계형 데이터베이스처럼 컬럼별로 나누는 것이 아닌 횡별로 나누어 샤드에 저장.) 여러 샤드에 분산 배치하여 병렬화 함으로써 성능 및 처리량을 늘릴 수 있다.  Primary Shard 와 Replica Shard Primary Shard Primary Shard 는 Indexing 되어 들어온 Document 의 원본 Shard 를 의미한다. \n Primary Shard 는 각 인덱스 별로 최소 1개 이상 존재해야 한다. ElasticSearch 에 Document 가 인덱싱 될 때 가장 처음에 생성되는 샤드이다. 샤드 개수를 지정하지 않는다면 기본으로 5 개로 지정된다.  Replica Shard Network / Cloud 환경의 샤드 노드가 오프라인 상태가 되거나 혹은 사라지게 될 경우를 대비하여 인덱스 샤드에 대해 하나 이상의 복사본을 생성할 수 있다. 이를 Replica Shard 라고 한다.\n ElasticSearch 에서 Primary Shard 가 인덱싱 된 후, Primary Shard 가 저장된 데이터 노드와는 다른 곳에 복제된다. Replica Shard 에도 넘버링을 하며, 어떤 Primary Shard 의 복제본인지 식별이 가능하다. replica 의 기본값은 1 인덱싱 시 Primary Shard 의 복제를 하는 과정이 추가된다.  단점  I/O 가 두배로 발생하여 인덱싱 성능이 저하 디스크 볼륨 또한 실제 도큐먼트 용량의 두배가 필요  [그림] ES 플러그인 인 Head 로 각 노드에 샤드 dashboard를 확인 할 수 있다. ( 진한테두리가 Primary Shard )\n+ Elasticsearch 의 샤드는` Lucene 의 인덱스` 이며, 단일 Lucene 인덱스가 포함할 수 있는 도큐먼트의 최대 개수는 **2,147,483,519** 개 이다. + Replica Shard 가 있기 때문에 샤드/노드 오류가 발생하더라도 Elasticsearch 클러스터의 고가용성이 유지된다. + 모든 Replica Shard 에서 병렬 방식으로 검색을 실행할 수 있으므로 검색 처리량 확장 가능하다.  [참고]\n Elasticsearch Reference  "
},
{
	"uri": "/elasticsearch/3/page-3-3/",
	"title": "jvm.options",
	"tags": [],
	"description": "",
	"content": " jvm.options jvm.options 의 설정을 통해 JVM(Java Virtual Machine) 의 옵션을 변경할 수 있습니다. jvm.options 환경 설정 파일은 config/jvm.options(tar or zip 배포판) 또는 /etc/elasticsearch/jvm.options(rpm 패키지 설치) 에서 위치하고 있습니다.\nJVM Heap Size Configuration Elasticsearch 는 Java 기반이기 때문에 Heap 메모리를 어떻게 설정하느냐에 따라 성능에 큰 영향을 미치게 됩니다. 기본적으로 Elasticsearch 의 최소, 최대 Heap 사이즈는 2GB 설정되어 있습니다. 실제 운영환경에 따라서 Elasticsearch 에서 충분한 Heap 을 사용할 수 있도록 Heap Size 를 구성하는 것이 중요합니다.\n# Elasticsearch 와 Heapsize 아래는 jvm.options 에서 최소 및 최대 힙 사이즈 크기를 설정하는 예시입니다. # set the minimun heap size to 2GB -Xms2g # set the maximum heap size to 2GB -Xmx2g \n1. 최소 힙 크기(Xms) 와 최대 힙 크기(Xmx) 를 동일하게 설정하는 것을 권고합니다. \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;힙 크기가 크면 클 수록 많은 데이터를 힙 영역에서 사용할 수 있으나 GC (Garbage Collection) 발생에 대한 JVM 의 성능 저하 및 정지에 대한 이슈를 고려해야 합니다. (Stop the world)\n2. 최대 힙 크기(Xmx) 를 실제 물리메모리(RAM) 에 50 % 를 넘지 않도록 권고합니다. \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\n3. 힙 크기는 32G 를 넘지 않도록 권고 하고 있습니다. JVM 은 데이더(Object) 에 접근하기 위한 메모리상의 주소를 OOP(Ordinary Object Pointer) 라는 구조체로 저장합니다. OOP 는 아키텍쳐에 따라 32bit 와 62bit 크기의 주소값을 참조하게 됩니다. 32bit 환경에서 2^32 (= 4GB) 의 주소값을 나타낼 수 있고 64 bit 환경에서는 2^64(=18EB) 까지의 주소값을 표시 할 수 있습니다. 64bit 환경에서는 메모리의 참조 영역이 넓기 때문에 성능이 떨어질 수 밖에 없습니다. 이러한 문제 때문에 JVM 은 32bit 기반의 OOP 를 이용하며 Heap 영역이 4GB 를 넘어가는 경우에 메모리 주소의 offset 을 가리키는 Compressed OOP 를 활용합니다. Compressed OOP 의 경우 메모리 주소의 Offset 을 가리키게 되며 이 오프셋은 8의 n 배수로 계산되어 기존 OOP 보다 8 배 더 많은 32GB 참조가 가능합니다.\n   JVM option Description     -XX:+UseConcMarkSweepGC 기본적으로 CMS GC 옵션을 사용.   -XX:CMSInitiatingOccupancyFraction old generation 힙 공간의 사용량을 지정하여 CMS GC 주기를 설정할 수 있다.  ex) -XX:CMSInitiatingOccupancyFraction=75 이면 old generation 75% 인 경우 CMS 주기를 시작하라는 의미.   -XX:+UseCMSInitiatingOccupancyOnly GC 통계를 따르지 않고 CMSInitiatingOccupancyFraction 을 기준으로 GC 주기를 시작   -XX : HeapDumpOnOutOfMemoryError OOM(Out of Memory) 등으로 더이상 힙 영역을 할당할 수 없는 경우 Heap Dump 를 생성하는 옵션   -XX:HeapDumpPath Heap Dump를 저장할 경로를 지정  ex) -XX:HeapDumpPath=/var/lib/elasticsearch   -XX:ErrorFile=filename 심각한 오류 로그(JVM Fatal Error logs를 받을 수 있는 경로를 지정  -XX:ErrorFile=/var/log/elasticsearch/hs_err_pid%p.log    "
},
{
	"uri": "/elasticsearch/3/",
	"title": "3 Week",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/spring5.0/11/page-11-2/",
	"title": "11.2 Spring Reactive - 1",
	"tags": [],
	"description": " 자바의 리액티브 프로그래밍 - 리액티브 스트림, 리액터 ",
	"content": " 11.2 Spring Reactive - 1 1. 리액티브 스트림 1.1 리액티브 스트림 의존성 추가 implementation (\u0026#39;org.reactivestreams:reactive-streams:1.0.2\u0026#39;) implementation (\u0026#39;org.reactivestreams:reactive-streams-tck:1.0.2\u0026#39;) 1.2 리액티브 스트림의 구성요소  Publisher : 데이터 제공자. 구독한 구독자들에게 구독 정보를 토대로 데이터를 제공한다. Subscriber : 데이터 소모자. 제공자로부터 데이터를 받아 소모한다. Subscription : 구독 정보. Subscriber 는 Publisher 를 구독하여 데이터(n) 요청할 수 있다.  // Publisher package org.reactivestreams; public interface Publisher\u0026lt;T\u0026gt; { void subscribe(Subscriber\u0026lt;? super T\u0026gt; var1); } // Subscriber package org.reactivestreams; public interface Subscriber\u0026lt;T\u0026gt; { void onSubscribe(Subscription var1); void onNext(T var1); void onError(Throwable var1); void onComplete(); } // Subscription package org.reactivestreams; public interface Subscription { void request(long var1); void cancel(); } Publisher  void subscribe(Subscriber\u0026lt;? super T\u0026gt; var1); : Subscriber 객체를 매개변수로 입력받아 Publisher 가 Subscriber 관리 할 수 있다. 그리고 Subscriber 의 메소드를 사용할 수 있다.\n  Subscriber  onSubscribe() : Publisher 를 구독하게 되면 호출된다. onNext() : 비동기 식으로 Executor 를 통해 구독자에게 메세지를 게시할 수 있다. onError() : 에러가 발생 시 호출된다. onComplete() : 더 게시된 메세지 요소가 없을 경우 다음 작업을 수행한다.  Subscription  request() : Publisher 에게 게시된 데이터를 요청한다. cancel() : 데이터에 대한 요청을 취소한다.  출처 및 참고 사이트  Java9 Reactive Stream API  http://www.reactive-streams.org/  Java9 Reactive Stream 에 대한 자세한 설명 및 내용 참고  http://jess-m.tistory.com/18 https://grokonez.com/java/java-9/java-9-flow-api-reactive-streams   2. 리액터 리액터는 스프링 피보탈 팀의 리액티브 프레임워크이며, 리액티브 스트림을 기반으로 한다.\n2.1 의존성 추가 # build.gradle\nimplementation (\u0026#39;io.projectreactor:reactor-core:3.2.5.RELEASE\u0026#39;) testImplementation (\u0026#39;io.projectreactor:reactor-test:3.2.5.RELEASE\u0026#39;)plugins { id \u0026#39;java\u0026#39; id \u0026#39;war\u0026#39; id \u0026#39;org.springframework.boot\u0026#39; version \u0026#39;2.1.1.RELEASE\u0026#39; } apply plugin: \u0026#39;java\u0026#39; apply plugin: \u0026#39;io.spring.dependency-management\u0026#39; group \u0026#39;com.mastering.spring\u0026#39; version \u0026#39;1.0-SNAPSHOT\u0026#39; sourceCompatibility = 1.11 repositories { mavenCentral() } dependencies { implementation (\u0026#39;org.springframework.boot:spring-boot-starter\u0026#39;) implementation (\u0026#39;org.reactivestreams:reactive-streams:1.0.2\u0026#39;) implementation (\u0026#39;org.reactivestreams:reactive-streams-tck:1.0.2\u0026#39;) implementation (\u0026#39;io.projectreactor:reactor-core:3.2.5.RELEASE\u0026#39;) testImplementation (\u0026#39;io.projectreactor:reactor-test:3.2.5.RELEASE\u0026#39;) testImplementation (\u0026#39;org.springframework.boot:spring-boot-starter-test:2.1.2.RELEASE\u0026#39;) testImplementation (\u0026#39;junit:junit:4.12\u0026#39;) } 2.2 Mono 와 Flux Mono 와 Flux 모두 Reactive Stream 의 Publisher 인터페이스를 구현하고 있으며, Reactor 에서 제공하는 여러 연산자(operators) 의 조합을 통해 스트림을 가공할 수 있다.\n Mono : 요소가 아예 없거나 하나의 결과만을 처리하기 위한 Reactor 객체 Flux : 결과가 0-N 개인 여러 개의 결과를 처리하는 Reactor 객체  package com.mastering.spring.reactive; import org.junit.Test; import reactor.core.publisher.Mono; import java.time.Duration; public class SpringReactiveTest { @Test public void monoExample() throws InterruptedException { // 5초 후에 하나의 요소를 방출한다.  Mono\u0026lt;String\u0026gt; stubMonoWithADelay = Mono.just(\u0026#34;Ranga\u0026#34;).delayElement(Duration.ofSeconds(5)); // 모노 이벤트를 수신하고 콘솔에 기록한다.  stubMonoWithADelay.subscribe(System.out::println); // 테스트 실행시간을 지연시킨다.  Thread.sleep(10000); } }/** * Consumer 를 명시적으로 정의 */ class SystemOutConsumer implements Consumer\u0026lt;String\u0026gt; { @Override public void accept(String s) { System.out.println(\u0026#34;Received \u0026#34; + s + \u0026#34; at\u0026#34; + new Date()); } }// 모노 이벤트를 수신하고 콘솔에 기록한다. // stubMonoWithADelay.subscribe(System.out::println); stubMonoWithADelay.subscribe(new SystemOutConsumer());class WelcomeConsumer implements Consumer\u0026lt;String\u0026gt; { @Override public void accept(String s) { System.out.println(\u0026#34;Welcome \u0026#34; + s); } }// 모노 이벤트를 수신하고 콘솔에 기록한다. // stubMonoWithADelay.subscribe(System.out::println); stubMonoWithADelay.subscribe(new SystemOutConsumer()); stubMonoWithADelay.subscribe(new WelcomeConsumer());@Test public void simpleFluxStream() { Flux\u0026lt;String\u0026gt; stubFluxStream = Flux.just(\u0026#34;Jane\u0026#34;, \u0026#34;Joe\u0026#34;); stubFluxStream.subscribe(new SystemOutConsumer()); } }"
},
{
	"uri": "/spring5.0/6/page-6-2/",
	"title": "6.2 HATEOAS",
	"tags": [],
	"description": "스프링부트 프로젝트로 hypermedia-driven REST web service 를  HATEOAS 로 적용해 보기",
	"content": " 6.2 HATEOAS REST 성숙도 모델 (Richardson Maturity Model) Richardson Maturity Model 에서는 Restful Web Service 를 다음의 단계로 나누어 성숙도를 정의하고 있다.\n Level 0 : 원격 프로시저 호출 (Remote Procedure Invocation) 에 기반한 형태로 resource 구분 없이 설계된 HTTP API  ex) http://server/getPosts, http://server/deletePosts, http://server/doThis, http://server/doThat 등\n Level 1 : resource 를 URI 통해 나타낸다. (명사 사용) 그러나, HTTP METHOD(GET,POST,PUT,DELETE 등) 사용하지 않는다.  ex) http://server/accounts, http://server/accounts/10\n Level 2 : resource 를 URI + HTTP Method 를 사용하여 접근한다.  ex) 계정을 수정하려면 PUT, 계정을 생성하려면 POST 메서드를 수행한다.\n Level 3 : HATEOAS. 요청한 정보 뿐만 아니라 요청한 정보에 관련한 URI 를 포함함으로써, 서비스 소비자가 할 수 있는 다음 조치에 대해서도 제공한다.\n  HATEOAS HATEOAS (Hypermedia as the Engine of Application State) 는 RESTful 아키텍쳐를 고유하게 유지하는 REST 응용 프로그램 아키텍쳐의 제약 사항이다.\nHypermedia 라는 용어는 이미지, 텍스트, 동영상 등 다른 형식의 미디어에 대한 링크가 포함된 것을 의미한다. Hypermedia 의 유사한 개념을 RESTful 서비스에도 적용하여, 요청한 리소스에 대한 데이터 뿐만 아니라 관련 리소스 또는 의존 리소스의 URI 링크 를 응답에 포함시켜 서비스 소비자에게 제공하는 형태라고 볼 수 있다.\n기존 RESTful API 의 단점  API 의 엔드포인트가 정해지면 이를 쉽게 변경하기가 어렵다. API 가 변경됨에 따라 이를 사용하는 모든 클라이언트 들이 함께 수정되어야 한다. API 가 수정되어야 하는 경우 API URL 에 버전명을 추가하거나 다른 API 를 지속적으로 추가하게 된다. 그렇게 되면 API URL 관리가 어려워진다. REST API 에 특정 작업을 수행하기 위해 데이터를 수집해야 한다거나, 해당 작업이 가능한지 여부를 판단하는 로직 모두 클라이언트에서 가져가야 한다.  HATEOAS 스프링부트에 적용하기 1. 의존성 추가하기 스프링 부트에는 spring-boot-starter-hateoas 라는 HATEOAS 를 위한 스타터를 제공한다. 따라서 관련 종속성을 pom.xml 또는 build.gradle 에 추가한다.\npom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-hateoas\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 또는 build.gradle implementation (\u0026#39;org.springframework.boot:spring-boot-starter-hateoas\u0026#39;) 아래는 spring-boot-starter-hateoas 의 중요한 의존성 중 하나는 HATEOAS 기능을 제공하는 spring-hateoas 이다.\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.hateoas\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-hateoas\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.25.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.plugin\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-plugin-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2. 리소스 링크를 반환하는 컨트롤러 구성 Response 값에 {name} 에 관련된 모든 응답을 검색하기 위한 링크를 반환하도록 설정한다. 기존 ResponseEntity 대신 Resource\u0026lt;Todo\u0026gt; 객체를 리턴하도록 소스를 수정한다.\nResource class 로 도메인 객체를 wrapping 해주고 link 를 추가할 수 있다. @GetMapping(\u0026#34;/users/{name}/todos/{id}\u0026#34;) public Resource\u0026lt;Todo\u0026gt; retrieveTodo(@PathVariable String name, @PathVariable int id) { Todo todo = todoService.retrieveTodo(id); if( todo == null ) { throw new TodoNotFoundException(\u0026#34;Todo Not Found.\u0026#34;); } // Todo 객체에 대한 리소스 객체를 생성한다.  Resource\u0026lt;Todo\u0026gt; todoResource = new Resource\u0026lt;Todo\u0026gt;(todo); // 현재 컨트롤러의 Name 관련한 모든 할일 목록을 조회하는 링크를 parent 항목으로 추가한다.  ControllerLinkBuilder linkBuilder = linkTo(methodOn(this.getClass()).retrieveTodos(name)); todoResource.add(linkBuilder.withRel(\u0026#34;parent\u0026#34;)); return todoResource; } 3. 응답에 HATEOAS 링크 정보 확인하기 curl 명령어 혹은 POSTMAN 으로 요청한다.\ncurl http://localhost:8080/users/Jack/todos/1{ \u0026#34;id\u0026#34;: 1, \u0026#34;user\u0026#34;: \u0026#34;Jack\u0026#34;, \u0026#34;desc\u0026#34;: \u0026#34;Learn Spring MVC\u0026#34;, \u0026#34;targetDate\u0026#34;: \u0026#34;2018-12-25T07:59:23.073+0000\u0026#34;, \u0026#34;done\u0026#34;: false, \u0026#34;_links\u0026#34;: { \u0026#34;parent\u0026#34;: { \u0026#34;href\u0026#34;: \u0026#34;http://localhost:8080/users/Jack/todos\u0026#34; } } } 해당 URL 을 요청하면 _links 키 값에 모든 할일을 조회할 수 있는 링크가 포함된다.\n참고한 사이트  Building a Hypermedia-Driven RESTful Web Service - https://spring.io/guides/gs/rest-hateoas/ Hypermedia-driven REST API : https://m.blog.naver.com/tmondev/220391644590 [한글화 프로젝트] 1. Richardson 성숙도 모델(Richardson Maturity Model) : http://jinson.tistory.com/190 On choosing a hypermedia type for your API - HAL, JSON-LD, Collection+JSON, SIREN, Oh My! - https://sookocheff.com/post/api/on-choosing-a-hypermedia-format/  "
},
{
	"uri": "/spring5.0/",
	"title": "Mastering Spring 5.0",
	"tags": [],
	"description": "",
	"content": " Mastering Spring 5.0  Mastering Spring 5.0 공부하면서 책 내용 정리  예제 Git Repository  https://github.com/PacktPublishing/Mastering-Spring-5.0  Table of Contents  Evolution to Spring Framework 5.0 Dependency Injection Building a Web Application with Spring MVC Evolution toward Microservices and Cloud-Native Applications Building Microservices with Spring Boot Extending Microservices Advanced Spring Boot Features Spring Data Spring Cloud Spring Cloud Data Flow Reactive Programming Spring Best Practices Working with Kotlin in Spring  "
},
{
	"uri": "/jpa-programming/",
	"title": "JPA Programming",
	"tags": [],
	"description": "",
	"content": " 자바 ORM 표준 JPA 프로그래밍 Table of Contents  1장 - JPA 소개 2장 - JPA 시작 3장 - 영속성 관리  "
},
{
	"uri": "/elasticsearch/1/page-1-3/",
	"title": "1.3 Distributed Cluster",
	"tags": [],
	"description": "클러스터 구성 시나리오",
	"content": " 1.3 Distributed Cluster 클러스터 구성 시나리오 1. 단일 노드에 3개의 샤드로 클러스터 구성하기 blogs 라는 인덱스에 3 개의 Primary 샤드와 1개의 Replica 샤드가 운용되도록 할당한다.\ncurl -X PUT \u0026#34;localhost:9200/blogs\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d { \u0026#34;settings\u0026#34; : { \u0026#34;number_of_shards\u0026#34; : 3, \u0026#34;number_of_replicas\u0026#34; : 1 } }  클러스터는 정상적으로 작동되나, 하드웨어의 오류가 발생할 경우 데이터 손실의 위험이 있다. 데이터 적재량이 많을 경우 싱글노드가 허용하는 볼륨을 모두 소진할 수도 있어 더이상 적재가 불가능 할 수도 있다.  2. 두번째 노드를 시작하여 두번째 노드에 Replica Shard 가 복제되도록 설정한다.  두 번째 노드가 클러스트에 추가되고, 두 번째 노드에는 각 샤드의 Replica Shard 가 생성된다.  3. 부하분산을 위하여 샤드를 재할당  어플리케이션의 수요가 증가함에 따라 노드를 확장 할 수 있다.Primary Shard 3개, Replica Shard 가 3개 이므로 최대 6개의 노드로 확장이 가능하다. 세번째 노드를 시작하여 노드가 분산되어 할당될 수 있도록 한다.   Node3 을 시작하게 되면 2개의 샤드가 Node3 으로 이동되었으며, 각 하드웨어의 리소스(CPU, RAM, I/O) 가 더 적은 수의 샤드에 공유되므로 각 샤드의 성능이 향상된다. 그러나 만약 한 대의 노드에서 Fail 이 발생할 경우 데이터의 안정성을 보장할 수 없다. 복제본 Replica Shard 의 개수를 추가한다. 기본 Replica Node 수를 2 개로 변경한다.  PUT /blogs/_settings { \u0026#34;number_of_replicas\u0026#34; : 2 }  위의 노드 구성을 통해 Node 2 개가 Fail 이 발생하여도 데이터의 손실은 막을 수 있다.  4. 노드 한 대가 Fail 이 발생했을 경우  Master 노드였던 Node1 번에 Fail 이 발생한다면, 가장먼저 노드간 새로운 Master 노드를 선출한다. 남아있는 나머지 노드들의 Replica Shard가 Primary Shard 로 승격되게 된다.  5. 죽였던 Node1 번을 다시 Active 시킨다면, 나머지 노드들의 Primary Shard 를 재 복제하여 Replica Shard 로 만든다. [참고]\n Elasticsearch Reference - distributed cluster   "
},
{
	"uri": "/elasticsearch/3/page-3-4/",
	"title": "log4j2.properties",
	"tags": [],
	"description": "",
	"content": " log4j2.properties Elasticsearch 는 logging 을 위해 Log4j 2 를 사용합니다. Log4j 2는 log4j2.properties 파일을 사용하여 구성할 수 있습니다.\n로그참조 파일 ${sys:es.logs.base_path}  로그의 Base 디렉토리 입니다. elasticsearch.yml 의 path.log 에 설정된 경로 입니다.  ${sys:es.logs.cluster_name}  클러스트 이름을 나타냅니다. elasticsearch.yml 의 cluster.name 으로 설정할 수 있습니다.  ${sys:es.logs.node_name}  노드의 이름을 나타냅니다. elasticsearch.yml 의 node.name 으로 설정할 수 있습니다.   ex) ${sys:es.logs.base_path}${sys:file.separator}${sys:es.logs.cluster_name}.log /var/log/elasticsearch/mycluster.log\n "
},
{
	"uri": "/spring5.0/11/page-11-3/",
	"title": "11.3 Spring Reactive - 2",
	"tags": [],
	"description": " 자바의 리액티브 프로그래밍 - 스프링 웹 리액티브  ",
	"content": " 11.2 Spring Reactive - 2 3. 스프링 웹 리액티브 스프링 웹 리액티브는 스프링 프레임워크 5 의 새로운 기능 중 하나이다. 이 기능은 웹 애플리케이션의 리액티브 기능을 제공한다. 스프링 웹 리액티브는 스프링 MVC 와 동일한 기본 프로그래밍 모델을 기반으로 한다.\n3.1 웹 리액티브 스트림 의존성 추가 implementation (\u0026#39;org.springframework.boot:spring-boot-starter-webflux\u0026#39;) 3.2 리액티브 컨트롤러 생성 @RestController public class StockPriceEventController { @GetMapping(\u0026#34;/stocks/price/{stockCode}\u0026#34;) Flux\u0026lt;String\u0026gt; retrieveStockPriceHardcoded(@PathVariable(\u0026#34;stockCode\u0026#34;) String stockCode) { return Flux.interval(Duration.ofSeconds(5)) .map(l -\u0026gt; getCurrentDate() +\u0026#34; : \u0026#34; + getRandomNumber(100, 125)).log(); } private String getCurrentDate() { return (new Date()).toString(); } private int getRandomNumber(int min, int max) { return ThreadLocalRandom.current().nextInt(min, max + 1); } } 3.3 HTML 뷰 생성 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt; \u0026lt;button id=\u0026#34;subscribe-button\u0026#34;\u0026gt;Get Latest IBM Price\u0026lt;/button\u0026gt; \u0026lt;ul id=\u0026#34;display\u0026#34;\u0026gt;\u0026lt;/ul\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;script\u0026gt; addEvent(\u0026#34;click\u0026#34;, document.getElementById(\u0026#39;subscribe-button\u0026#39;), () =\u0026gt; registerEventSourceAndAddResponseTo(\u0026#34;/stocks/price/IBM\u0026#34;, \u0026#34;display\u0026#34;)); function registerEventSourceAndAddResponseTo(uri, elementId) { let stringEvents = document.getElementById(elementId); let stringEventSource = new EventSource(uri) stringEventSource.onmessage = (e) =\u0026gt; { let newElement = document.createElement(\u0026#34;li\u0026#34;); newElement.innerHTML = e.data; stringEvents.appendChild(newElement); } } function addEvent(event, elem, func) { if (typeof (EventSource) !== \u0026#39;undefined\u0026#39;) { elem.addEventListener(event, func, false); } else { elem[event] = func; } } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;"
},
{
	"uri": "/spring5.0/6/page-6-3/",
	"title": "6.3 Bean Validation",
	"tags": [],
	"description": "스프링 부트의 Bean Validation 설정에 관련한 내용을 정리",
	"content": " 6.3 Bean Validation Bean Validation 데이터 유효성 검증 (Validation) 은 모든계층에서 공통적으로 발생하는 작업이다. 만약 모든 계층에서 동일한 내용의 Validation 로직이 각각의 레이어별로 구현되어 있다면 코드 중복과 함께 각 계층별로 중구난방으로 구현된 검증로직간 불일치로 인하여 오류가 발생하기도 쉽다.\n이러한 Validation 중복을 피하기 위해 도메인의 검증 로직을 도메인 모델 자체에 묶어서 정의하기도 한다. 하지만 도메인 모델에 실제 코드로 Validation 로직을 표현한다면 도메인 모델 자체가 장황하지고 복잡해지게 된다.\nJava 에서는 위와 같은 문제를 해결하기 위해 어노테이션을 통한 Entity 와 Method 를 검증하기 위한 API 를 제공하고 있다.\nBean Validation 은  어노테이션을 통해 객체 모델에 대한 제약 조건을 표현 할 수 있다. 확장 가능한 방식으로 사용자 정의 제약 조건을 작성할 수 있다. 개체 및 개체 그래프를 검증하기 위한 API 를 제공한다. 메서드 및 생성자의 매개 변수를 확인하고 반환 값을 리턴하는 API 를 제공한다. 현지화 된 언어로 위반 사항을 보고한다.  Hibernate Validator Hibernate Validator 는 Bean Validation 명세에 대한 구현체이다. Bean Validation 2.0 에 대한 구현은 Hibernate Validator 6.0.1.Final 이며 Spring Boot 2.0 이상에서 이것을 사용하고 있다.\n1.스프링 부트로 Bean Validation 시작하기 1.1 프로젝트 설정 Hibernate Validator 는 spring-boot-web-start 프로젝트의 의존성으로 정의 된다.\n org.hibernate.validator:hibernate-validator:6.0.13.Final javax.validation:validation-api:2.0.1.Final  1.2 컨트롤러 메서드에 Bean Validation 활성화 Controller 메서드의 매개 변수에 @Valid 어노테이션을 추가함으로 유혀성 검사를 트리거 할 수 있도록 활성화 시킬 수 있다. 아래의 경우 POST 요청으로 들어온 매개변수를 바인딩 한 뒤 Todo 빈에 정의된 Validation 에 따라 유효성 검증을 하게 된다.\n@RequestMapping(method = RequestMethod.POST, path = \u0026#34;/users/{name}/todos\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; add(@PathVariable String name, @Valid @RequestBody Todo todo) { Todo createTodo = todoService.addTodo(name, todo.getDesc(), todo.getTargetDate(), todo.isDone()); if(createTodo == null) { return ResponseEntity.noContent().build(); } URI location = ServletUriComponentsBuilder.fromCurrentRequest().path(\u0026#34;/{id}\u0026#34;).buildAndExpand(createTodo.getId()).toUri(); return ResponseEntity.created(location).build(); } 1.3 도메인 객체에 Bean Validation 정의 public class Todo { private int id; @NotNull private String user; @Size(min = 9, message = \u0026#34;Enter at least 10 Characters.\u0026#34;) private String desc; // getter setter }  @NotNull - user 필드의 값이 비어 있지 않은지 확인한다. @Size(min = 9, message = \u0026ldquo;Enter at least 10 Characters.\u0026rdquo;) - desc 필드 값의 문자가 9 자 이상인지 확인한다.  Bean 을 검증하는 데 사용할 수 있는 어노테이션은 많다. 다음은 몇 가지 Bean Validation 어노테이션이다.\n @AssertTrue, @AssertFalse - 어노테이션 정의 된 필드 값이 true 혹은 false 인지 확인 한다. @Future - 어노테이션 정의 필드 된 값이 미래 날짜여야 한다. @Past - 어노테이션 정의 필드 값이 과거의 날짜여야 한다. @Max - 어노테이션 정의 필드 값이 지정된 최대값 보다 작거나 같은 숫자여야 한다. @Min - 어노테이션 정의 필드 값이 지정된 최소값 보다 크거나 같은 숫자여야 한다. @NotNull - 어노테이션 정의 필드 값이 null 이면 안된다. @Pattern - 어노테이션 정의 필드 값의 {@code CharSequence} 요소는 지정된 정규 표현식과 일치해야 한다. 정규표현식은 자바 정규 표현식 규칙을 따른다. @Size - 어노테이션 정의 필드 값의 크기는 지정된 범위 내에 있어야 한다.  참고 사이트  beanvalidation.org - https://beanvalidation.org/  "
},
{
	"uri": "/fluent-python/",
	"title": "Fluent Python",
	"tags": [],
	"description": "",
	"content": " 전문가를 위한 파이썬 내가 전문가가 아닌게 함정\u0026hellip; Table of Contents  Part 2 데이터 구조체  2. 시퀀스   "
},
{
	"uri": "/elasticsearch/1/page-1-4/",
	"title": "1.4 Basic Concepts - Segment",
	"tags": [],
	"description": "Elasticsearch 개념 및 용어정리 - Inverted Index, Segment",
	"content": " 1.4 Basic Concepts - Segment Inverted Index 전통적인 데이터베이스는 필드당 하나의 값을 저장하기 때문에 전체 텍스트 검색에는 적합하지 않다. 즉 다중 값을 색인화 할 수 있어야 하는데, Elasticsearch 에서는 Inverted Index 형태의 인덱싱을 통해 Full-text Search 가 가능하도록 했다. 모든 문서에서 발생하는 모든 고유 값 또는 용어의 정렬된 목록을 포함하며, 각 용어에 대해 이를 포함하는 모든 문서 목록을 표시한다.\nFull-text Search (전체 텍스트 검색) 는 요청한 모든 단어를 문서 또는 데이터베이스에서 모든 단어와 비교하는 포괄적 인 검색 방법이다. 전체 텍스트 쿼리에는 간단한 단어와 구 또는 여러 형식의 단어나 구가 포함될 수 있으며, 텍스트 쿼리는 일치 항목이 하나 이상 있는 문서를 모두 반환한다.\nTerm | Doc 1 | Doc 2 | Doc 3 | ... ------------------------------------ brown | X | | X | ... fox | X | X | X | ... quick | X | X | | ... the | X | | X | ...   Inverted Index 는 단어가 포함된 문서 목록 뿐만아니라 단어의 관련성 혹은 유사성 ( 각 단어를 포함하는 문서의 수, 특정 문서에 단어가 나타나는 횟수, 각 문서의 단어 순서, 각 문서의 길이, 모든 문서의 평균 길이 등) 의 정보를을 저장할 수 있으며 이러한 통계를 통해 중요도 혹은 어떤 문서(document)가 중요한지 결정할 수 있다.\n 초기에는, 하나의 거대한 Inverted Index 가 전체 문서 모음을 위해 디스크에 쓰여진다. 새 색인이 준비되게 되면 이전 색인이 바뀌고 최근 변경사항을 검색 할 수 있게 된다.\n  Immutable (불변성)  디스크에 쓰여진 Inverted Index 는 변경이 불가한 불변의(Immutable) 특성을 갖고 있다.  불변성의 이점  Data lock 을 걸 필요없이 일관성을 유지할 수 있다. : 동시에 변경을 시도하는 여러 프로세스에 대해 주의할 필요 없음. 전체 Index 가 버퍼 캐시에 로드 가능하다면, 변경이 없는 경우 항상 메모리에 로드된 상태이며 이는 File I/O 가 아닌 메모리 캐시를 통해 접근되므로 성능이 향상 된다. Inverted Index 를 작성하게 되면 데이터를 압축 할 수 있으므로 리소스 소모가 높은 디스크 I/O 를 줄이고 캐시하는데 필요한 RAM 의 용량을 줄일 수 있다.  불변성의 단점  말그대로 Update 가 불가능하다. 새 문서를 검색 가능하게 하려면 전체 색인을 다시 작성해야 한다. 다시 작성해야 하기 때문에 인덱스에 포함 할 수 있는 데이터 양이나 업데이트 빈도에 상당한 제한이 있다.  어떻게 불변성의 이점을 잃지 않고 Inverted Index 를 갱신할 수 있을까?  전체 Inverted Index 를 재작성하는 대신, 변화된 데이터를 나타내는 새로운 보조 인덱스를 추가한다. 검색 요청이 발생하면, 가장 오래된 인덱스부터 시작하여 결과를 조합하여 리턴한다.  Segment  Segment 는 하나의 Inveted Index 를 의미하지만, commit point 를 갖는 모든 추가된 Inverted Index 를 의미한다. [그림1] Document 가 인덱싱 될 때 시스템 버퍼 캐시에 먼저 적재된다.  [그림2] 이후, 디스크의 Segment 에 기록된다. 이 상태에서 refresh 를 거쳐야 commit point 가 생성되어 검색 가능한(searchable) 상태로 전환된다.   [참조]\n Elasticsearch Reference - inside-a-shard\n Elasticsearch Reference - dynamic-indices \n  "
},
{
	"uri": "/elasticsearch/3/page-3-5/",
	"title": "그 외 설정",
	"tags": [],
	"description": "",
	"content": " Other Settings vi /etc/security/limits.conf Elasticsearch 는 많은 파일을 쓰거나 핸들링 하게 됩니다. 열 수 있는 File Descriptor 가 부족하면 데이터의 손실로 이어질 수 있으며 실행할 수 있는 최대 File Descriptor 를 65,536 개 이상으로 설정하도록 합니다.\nvi /etc/security/limits.conf elasticsearch soft nofile 65536 elasticsearch hard nofile 65536\nThread 수 Elasticsearch 는 여러 유형의 작업에 대해 많은 Thread Pool 을 사용합니다. Elasticsearch 사용자가 만들 수 있는 Thread 가 4096 개 이상인지 확인합니다. elasticsearch soft noproc 4096 elasticsearch hard noproc 4096\nSysconfig file RPM 또는 Debian 패키지를 사용하여 시스템 설정 및 환경 변수를 지정할 수 있습니다. /etc/sysconfig/elasticsearch\nVirtual Memory Elasticsearch 는 기본적으로 Index 를 저장하기 위해 FileSystme을 사용하기 위한 mmmap 을 사용합니다. mmap의 개수는 기본 운영체제의 제한이 너무 낮아 메모리 부족 예외를 발생시키기도 합니다.\nsudo vi /etc/sysctl.conf vm.max_map_count=22144\nsudo sysstl -p Swap disabling 일반적으로 JVM 옵션에서 메모리 사용이 제어되므로 Swap 을 활성시킬 필요는 없습니다. 일시적으로 swap 을 비활성화 sudo swapoff -a\nswappiness configuration vm.swappiness 가 1로 설정되어 있는지 확인합니다. 이렇게 하면 swap 되는 경우가 줄어들고 일반적인 상황에서는 swapping으로 이어지지 않습니다.\n"
},
{
	"uri": "/spring5.0/6/page-6-4/",
	"title": "6.4 Swagger",
	"tags": [],
	"description": "스프링부트 프로젝트에 REST API 문서 자동화 툴인 swagger 적용",
	"content": " 6.4 Swagger REST 서비스 문서의 자동화  REST API 심플하게 설계되면 좋겠지만, 소비자의 요구사항 또는 서비스가 커짐에 따라 API 가 점점 복잡해지고 관리해야할 API 개수도 점점 늘게 된다. 협업을 위해서는 API 는 반드시 문서화 되어야 하는데, 소스 변경사항과 동기화 시키기가 매번 번거롭다. 이러한 문제를 해결하기 위해 REST API 서비스 문서(스펙)을 자동화 하는 툴이 등장하게 되었다.  주요 API Spec 자동화 라이브러리  SLATE : https://github.com/lord/slate Swagger : https://swagger.io/ API Blueprint : https://apiblueprint.org/  Swagger2 Swagger 2 는 RESTful API 를 설명하고 문서화하는데 사용되는 오픈소스 라이브러리이다. 특정 언어에 구애 받지 않으며, HTTP 이외에 새로운 기슬과 프로토콜 확장이 가능하다. HTML, Javasript CSS 를 통하여 API 문서를 동적으로 생성할 수 있는 Swagger UI 라이브러리가 함께 제공된다. Swagger2 Spec 은 몇 가지 구현체가 있는데, Springboot 프로젝트의 경우 Springfox 구현체가 주로 사용된다.\n스프링부트 프로젝트에 swagger 적용하기 1. 의존성 추가 Springfox Spec 의 Swagger 와 Swagger UI 를 pom.xml 또는 build.gradle 에 추가한다.\npom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; build.gradle implementation(\u0026#39;io.springfox:springfox-swagger2:2.9.2\u0026#39;) implementation(\u0026#39;io.springfox:springfox-swagger-ui:2.9.2\u0026#39;) 2. 스웨거 프로젝트 설정 /src/main/com/mastering/sping/springboot/config/SwaggerConfig.java @Configuration @EnableSwagger2 public class SwaggerConfig { @Bean public Docket api() { return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.any()) .paths(PathSelectors.any()).build(); } }  @Configuration : 스프링 구성파일을 정의한다. @EnableSwagger2 : 스웨거 지원을 가능하게 하는 어노테이션. Docket : 스웨서 스프링 MVC 프레임워크를 사용해 스웨거 문서 생성을 설정하는 간단한 Builder Class new Docket(DocumentationType.SWAGGER_2) : 스웨거 2를 사용할 스웨거 버전으로 설정한다. .apis(RequestHandlerSelectors.any()).paths(PathSelectors.any()) : 문서의 모든 API 와 경로를 포함한다.  3. 스웨거 API 명세 확인하기 Swagger 설정이 완료되면 서버를 기동 후, http://localhost:8080/v2/api-docs 로 스웨거 API 문서를 시작할 수 있다.\n4. 스웨거 UI 문서 확인하기 Swagger UI 는 의존성 라이브러리 io.springfox:springfox-swagger-ui 를 통해 활성화 된다. http://localhost:8080/swagger-ui.html 로 문서를 확인 할 수 있다.\n"
},
{
	"uri": "/elasticsearch/1/page-1-5/",
	"title": "1.5 Install Elasticsearch with RPM",
	"tags": [],
	"description": "Elasticsearch yum, rpm 설치",
	"content": " 1.5 Install Elasticsearch with RPM Elasticsearch 는 Java 언어로 이루어진 아파치 Lucene 기반으로 이루어져 있다. 그러므로, 설치를 위해서는 Java 가 먼저 설치되어 있어야 한다. ES 는 여러가지 방법으로 설치가능하지만 그중에서 RPM 패키지 관리자로 설치하는 방법에 대해 정리하였다.\n 다른 방법으로 ES 설치하기  yum 으로 설치하기 1) RPM Repository 등록하기 /etc/yum.repos.d/elasticsearch.repo : yum 저장소에 elastic 저장소를 수동으로 추가 한다.\n[elasticsearch-6.x]name=Elasticsearch repository for 6.x packagesbaseurl=https://artifacts.elastic.co/packages/6.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md  2) yum 명령어로 install yum install elasticsearch 수동으로 RPM 파일을 다운받아 설치하기 1) wget 으로 rpm 파일 내려받기 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.0.rpm 2) rpm 명령어로 설치 rpm -ivh elasticsearch-6.4.0.rpm Elasticsearch 서비스 시작하기 1. Elasticsearch 설정파일 Elasticsearch 의 3개의 설정파일이 존재한다.\n elasticsearch.yml : Elasticsearch 기본설정 jvm.options : Elasticsearch JVM 설정 log4j2.properties : Elasticsearch Logging 설정  elasticsearch.yml elasticsearch.yml 기본 설정 파일이다. YAML 형식으로 작성되어 있으며, 필요한 옵션을 수정할 수 있다.   /etc/elasticsearch/elasticsearch.yml\n# data 파일 경로와 log 파일의 경로를 수정하기.path.data:/var/lib/elasticsearchpath.logs:/var/log/elasticsearch 2. 서비스 시작하기 # init 사용 service elasticsearch start# systemd 사용 systemctl start elasticsearch.service "
},
{
	"uri": "/spring5.0/6/page-6-5/",
	"title": "6.5 Spring Security - Basic authentication",
	"tags": [],
	"description": "스프링 시큐리티로 REST 서비스 보호 - 기본 인증",
	"content": " 6.5 Spring Security - Basic authentication 스프링 시큐리티로 REST 서비스 보호 최근에는 서비스 시스템들끼리 REST API 기반의 통신이 많이 이루어지고 있다. 네이티브 앱과 서버 간 통신뿐만 아니라 자바스크립트 웹 클라이언트 와 서버간에도 REST API 통신을 많이 사용하기 때문에 REST 서비스(리소스) 에 대한 보안이 중요해 지고 있다.\n보안에서 중요한 기본 개념 - 인증(Authentication) 과 권한 (Authorization)  소비자(클라이언트) 가 서비스(리소스) 에 접근이 가능한 소비자인지 ? 인증(Authentication) 접근이 가능하지만 해당 작업을 소비자(클라이언트) 에게 허용할것인지 ? 인가/권한부여(Authorization)  인증방식은 다양하며, 전통적인 인증방식으로는 사용자명(Principle)과 비밀번호(Credential) 로 인증하는 Credential 기반 인증 방식 과 OTP 등과 같이 추가적인 인증방식을 도입해 2가지 방법으로 인증하는 이중 인증 방식 과 최근에는 OAuth2 인증방식 도 필수적으로 사용되고 있다.\n스프링에서는 Spring Security 를 사용하여 인증과 권한 프로세스 구현할 수 있다.\n스프링부트에서 인증방식 구현하기 스프링 시큐리티로 아래 두 가지 타입의 인증을 각각 구현해 본다.\n 기본인증 (Basic Authentication) OAuth 2.0 인증  1. 의존성 추가하기 spring-boot-starter-security 의존성을 pom.xml 또는 build.gradle 에 추가한다.\npom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; build.gradle implementation(\u0026#39;org.springframework.boot:spring-boot-starter-security\u0026#39;) spring-boot-starter-security 는 아래 세가지 의존성을 가져온다. 2. 기본인증  spring-boot-starter-security 는 기본적으로 모든 서비스에 대해 기본 인증을 자동으로 설정한다. 브라우저에서는 기본 로그인 페이지로 이동되거나, REST API 요청 시 응답 코드 401 을 리턴하게 된다. 기본 인증시 사용자 ID 는 user 이며, 패스워드는 보통 스프링 어플리케이션 기동 시 로그에 표시된다.   특정 ID 와 패스워드를 설정하려면 application.properties (또는 application.yml) 에 아래와 같이 구성할 수 있다.\napplication.yml spring:security:user:name:devtestpassword:devtest!@# 3. 통합 테스팅 @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = Chapter06Application.class, webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class TodoControllerIT { @LocalServerPort private int port; private String createUrl(String uri) { return \u0026#34;http://localhost:\u0026#34; + port + uri; } private TestRestTemplate template = new TestRestTemplate(); HttpHeaders headers = createHeaders(\u0026#34;devtest\u0026#34;, \u0026#34;devtest!@#\u0026#34;); private HttpHeaders createHeaders(String username, String password) { return new HttpHeaders() { { String auth = username + \u0026#34;:\u0026#34; + password; byte[] encodedAuth = Base64.getEncoder().encode(auth.getBytes(Charset.forName(\u0026#34;US-ASCII\u0026#34;))); String authHeader = \u0026#34;Basic \u0026#34; + new String(encodedAuth); set(\u0026#34;Authorization\u0026#34;, authHeader); } }; } @Test public void retrieveTodos() throws Exception { String expected = \u0026#34;[{\\\u0026#34;id\\\u0026#34;:1,\\\u0026#34;user\\\u0026#34;:\\\u0026#34;Jack\\\u0026#34;,\\\u0026#34;desc\\\u0026#34;:\\\u0026#34;Learn Spring MVC\\\u0026#34;,\\\u0026#34;targetDate\\\u0026#34;:\\\u0026#34;2018-12-26T14:57:05.021+0000\\\u0026#34;,\\\u0026#34;done\\\u0026#34;:false},{\\\u0026#34;id\\\u0026#34;:2,\\\u0026#34;user\\\u0026#34;:\\\u0026#34;Jack\\\u0026#34;,\\\u0026#34;desc\\\u0026#34;:\\\u0026#34;Learn Struts\\\u0026#34;,\\\u0026#34;targetDate\\\u0026#34;:\\\u0026#34;2018-12-26T14:57:05.021+0000\\\u0026#34;,\\\u0026#34;done\\\u0026#34;:false}]\u0026#34;; ResponseEntity\u0026lt;String\u0026gt; response = template.exchange(createUrl(\u0026#34;/users/Jack/todos\u0026#34;), HttpMethod.GET, new HttpEntity\u0026lt;String\u0026gt;(null, headers), String.class); JSONAssert.assertEquals(expected, response.getBody(), false); } }  HTTP 에서 Basic Authentication 인증은 HTTP 사용자 Agent (ex. 웹 브라우저) 가 요청할 때 사용자 이름과 암호를 제공하는 방법이다. 기본 HTTP 인증 요청 Header 필드에 Authorization: Basic \u0026lt;credentials\u0026gt; 형태로 포함된다. 여기서 credentials 은 콜론으로 결합 된 ID 및 암호의 base64 인코딩 형태이다.\n Authorization : https://developer.mozilla.org/ko/docs/Web/HTTP/Headers/Authorization\n  4. 단위 테스팅 단위 테스트에 보안을 사용하고 싶지 않다면 @WebMvcTest 어노테이션에 secure=false 파라미터를 추가한다.\n@RunWith(SpringRunner.class) @WebMvcTest(TodoController.class, secure = false) public class TodoControllerTest {"
},
{
	"uri": "/elasticsearch/1/page-1-6/",
	"title": "1.6 Installation with .zip/.tar.gz",
	"tags": [],
	"description": " zip 또는 .tar.gz 로 Window 환경에서 설치해보기",
	"content": " 1.6 Installation with .zip/.tar.gz Elasticsearch는 .zip 또는 .tar.gz 패키지로도 제공된다. 모든 시스템에 제한없이 가장 쉽게 설치할 수 있는 방법이다.\n 다른 방법으로 ES 설치하기 최신 버전 다운로드  .zip 패키지로 다운로드 및 설치하기 1. wget 으로 .zip 파일 다운로드 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.2.zip 2. zip 압축해제 unzip elasticsearch-6.4.2.zip .tar.gz 패키지로 다운로드 및 설치하기 wget 으로 .zip 파일 다운로드 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.2.tar.gz tar 압축해제 tar -xzf elasticsearch-6.4.2.tar.gz Command Line 에서 실행하기 ./bin/elasticsearch # running as a daemon ./bin/elasticsearch -d -p pid  Elasticsearch running 중 인지 확인하기  기동시 옵션으로 포트를 지정하지 않으면 기본 포트는 9200. curl 과같은 HTTP 요청으로 JSON 결과값이 올바르게 오는지 확인.  curl http://localhost:9200  "
},
{
	"uri": "/spring5.0/6/page-6-6/",
	"title": "6.6 Spring Security - OAuth 2.0",
	"tags": [],
	"description": "스프링 시큐리티로 REST 서비스 보호 - OAuth 2 인증",
	"content": " 6.6 Spring Security - OAuth 2.0 OAuth2 인증  OAuth 2는 어플리케이션과 Facebook, GitHub 및 DigitalOcean 과 같은 HTTP 서비스의사용자 계정에 대한 제한된 액세스 권한을 얻을 수있게 해주는 인증 프레임 워크이다. 이는 사용자 계정을 호스팅하는 서비스에 사용자 인증을 위임하고 타사 응용 프로그램에 사용자 계정에 대한 액세스 권한을 부여하여 작동하게 된다. OAuth 2는 웹 및 데스크톱 응용 프로그램 및 모바일 장치에 대한 인증 흐름을 제공하게 된다.  다음은 일반적인 OAuth2 교환에 중요한 사용자이다  리소스 소유자 (사용자) : 리소스 소유자는 자신의 계정에 액세스하기 위해 어플리케이션 을 인증하는 사용자 이다. 응용 프로그램의 사용자 계정의 액세스 권한은 부여 된 권한 (예 : 읽기 또는 쓰기 권한) 의 \u0026ldquo;범위\u0026rdquo;로 제한된다. 리소스 서버 : 리소스 서버는 사용자의 계정을 호스트하며 보안 유지가 필요한 리소스가 있는 서버이다. 클라이언트 : 클라이언트는 사용자 계정(사용자 계정을 호스트하는 리소스 서버) 액세스하려는 어플리케이션이다. 권한 서버 : OAuth 서비스를 제공하며, 사용자의 신원을 인증하며 클라이언트가 리소스 서버에 액세스 할 수 있는 권한을 부여한다.   어플리케이션은 사용자에게 리소스 서버 자원에 대한 액세스 권한을 요청한다. 사용자가 액세스 권한을 제공하면 어플리케이션은 권한을 부여 받는다. 어플리케이션은 사용자 권한 부여 및 자체 클라이언트 권한 정보를 권한 서버에 제공한다. 인증에 성공하면 인증을 위한 액세스 토큰을 제공한다. 어플리케이션은 인증을 위해 액세스 토큰을 제공하는 리소스 서버를 호출한다. 액세스 토큰이 유효하면 리소스 서버는 리소스 세부 정보를 반환한다.  Springboot OAuth 2 인증 구현하기 1. 의존성 추가 spring-security-oauth2 는 스프링 시큐리티에 OAuth2 지원을 제공하기 위한 모듈이다. pom.xml 또는 build.gradle 에 추가한다.\npom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security.oauth\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-oauth2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; build.gradle implementation(\u0026#39;org.springframework.security.oauth:spring-security-oauth2:2.3.4.RELEASE\u0026#39;) 2. 권한 및 리소스 서버 설정하기 일반적으로 권한 서버와 리소스 서버를 분리하지만, 예제 소스는 권한 서버와 리소스 서버를 동일하게 지정하였다.\n@EnableResourceServer @EnableAuthorizationServer @SpringBootApplication public class Chapter06Application { public static void main(String[] args) { SpringApplication.run(Chapter06Application.class, args); } }  @EnableResourceServer : 들어오는 OAuth 2 토큰을 통해 요청을 인증하는 스프링 시큐리티를 사용하는 OAuth2 리소스 서버에 대한 어노테이션이다. @EnableAuthorizationServer : DispatcherServlet 콘텍스트인 현재 어플리케이션 콘텍스트에서 AuthorizationEndpoint 및 TokenEndPoint 를 사용해 권한 부여 서버를 사용할 수 있도록 하는 어노테이션이다.  3. 권한 서버 세부 정보 구성하기 예제 소스에는 application.properties 를 통해 세부 구성을 설정을 하였지만, 자동구성 설정이 잘 되지 않아 @Configuration 을 통하여 수동 구성으로 작성하였다.\n Spring Boot 2.x 버전에서 OAuth2가 안될때 - https://hue9010.github.io/spring/OAuth2/\n AuthorizationServerConfigurerAdapter 를 상속받아 권한서버의 세부 사항을 구성한다.\n/src/main/java/com/mastering/spring/springboot/config/OAuthConfiguration.java  @Configuration public class OAuthConfiguration extends AuthorizationServerConfigurerAdapter { @Autowired @Qualifier(\u0026#34;authenticationManagerBean\u0026#34;) private AuthenticationManager authenticationManager; @Autowired private TestUserDetailService clientDetailsService; @Override public void configure(ClientDetailsServiceConfigurer configurer) throws Exception { configurer.inMemory() .withClient(\u0026#34;clientId\u0026#34;) .secret(\u0026#34;{noop}clientSecret\u0026#34;) .authorizedGrantTypes(\u0026#34;authorization_code\u0026#34;, \u0026#34;refresh_token\u0026#34;, \u0026#34;password\u0026#34;) .scopes(\u0026#34;openid\u0026#34;) .authorities(\u0026#34;ROLE_MY_CLIENT\u0026#34;); } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints.tokenServices(getDefaultTokenServices()) .authenticationManager(authenticationManager) .userDetailsService(clientDetailsService); } @Bean @Primary public DefaultTokenServices getDefaultTokenServices() { DefaultTokenServices tokenServices = new DefaultTokenServices(); tokenServices.setTokenStore(new InMemoryTokenStore()); return tokenServices; } }  void configure(ClientDetailsServiceConfigurer configurer) : 클라이언트 ID 와 Secret 자격증명 정보를 메모리에 설정한다. Spring Security 5.0.0.RC1 이후 암호변환정책이 변경되었으므로, 기본값인 DelegatingPasswordEncoder 에는 패드워드 암호화 메소드 접두어가 필요하다. (bcrypt/noop/pbkdf2/scrypt/sha256) 중 하나를 사용할 수 있으며, 예제는 따로 인코딩을 지정하지 않았기 때문에 {noop} 접두어를 설정함.\n void configure(AuthorizationServerEndpointsConfigurer endpoints) : /oauth/token 엔드포인트에 대한 상세 서비스를 지정할 수 있다.\n [spring-security] 5.0 에서 달라진 암호변환정책, DelegatingPasswordEncoder- https://java.ihoney.pe.kr/498\n https://spring.io/blog/2017/11/01/spring-security-5-0-0-rc1-released#password-encoding\n  /src/main/java/com/mastering/spring/springboot/config/WebSecurityConfigurer.java @Configuration public class WebSecurityConfigurer extends WebSecurityConfigurerAdapter { @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } src/main/java/com/mastering/spring/springboot/service/TestUserDetailService.java public class TestUserDetailService implements UserDetailsService { @Value(\u0026#34;${spring.security.user.name}\u0026#34;) private String myUserName; @Value(\u0026#34;${spring.security.user.password}\u0026#34;) private String myUserPassword; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { if(!myUserName.equals(username)) { throw new UsernameNotFoundException(\u0026#34;UsernameNotFound [\u0026#34; + username + \u0026#34;]\u0026#34;); } PasswordEncoder encoder = PasswordEncoderFactories.createDelegatingPasswordEncoder(); User.UserBuilder userBuilder = User.builder().passwordEncoder(encoder::encode); UserDetails user = userBuilder .username(myUserName) .password(myUserPassword) .roles(\u0026#34;USER\u0026#34;) .build(); return user; } }  UserDetailsService : 실제 DB 나 혹은 사용자 정보를 조회하여 리턴한다. 아래는 UserDetailsService 를 사용자 정의로 구현하여, 이전 예제에서 설정한 application.yml 에 있는 회원정보를 가져와 검증하도록 작성하였다.  4. OAuth 요청 실행 API 에 액세스 하려면 다음 2단계 프로세스가 필요하다.  액세스 토큰을 얻는다. 액세스 토큰을 사용해 요청을 실행한다.  액세스 토큰 얻기 액세스토큰을 이용한 요청 실행 5. 통합테스트 private OAuth2RestTemplate getOAuthTemplate() { ResourceOwnerPasswordResourceDetails resource = new ResourceOwnerPasswordResourceDetails(); resource.setUsername(\u0026#34;user-name\u0026#34;); resource.setPassword(\u0026#34;user-password\u0026#34;); resource.setAccessTokenUri(createUrl(\u0026#34;/oauth/token\u0026#34;)); resource.setClientId(\u0026#34;clientId\u0026#34;); resource.setClientSecret(\u0026#34;clientSecret\u0026#34;); resource.setGrantType(\u0026#34;password\u0026#34;); OAuth2RestTemplate oauthTemplate = new OAuth2RestTemplate(resource, new DefaultOAuth2ClientContext()); return oauthTemplate; } @Test public void retrieveTodo() throws Exception { String expected = \u0026#34;{id:1,user:Jack,desc:\\\u0026#34;Learn Spring MVC\\\u0026#34;,done:false}\u0026#34;; ResponseEntity\u0026lt;String\u0026gt; response = getOAuthTemplate().getForEntity(createUrl(\u0026#34;/users/Jack/todos/1\u0026#34;), String.class); JSONAssert.assertEquals(expected, response.getBody(), false); }  ResourceOwnerPasswordResourceDetails resource = new ResourceOwnerPasswordResourceDetails() : 사용자 자격증명과 클라이언트 자격증명으로 ResourceOwnerPasswordResourceDetails 설정한다.\n resource.setAccessTokenUri(createUrl(\u0026quot;/oauth/token\u0026quot;)) : 인증서버의 URL 을 구성한다.\n OAuth2RestTemplate oauthTemplate = new OAuth2RestTemplate(resource, new DefaultOAuth2ClientContext()) : OAuth2RestTemplate 은 OAuth2 프로토콜을 지원하는 Resttemplate 의 확장이다.\n  출처  https://oauth.net/2/ https://www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2  "
},
{
	"uri": "/elasticsearch/1/page-1-7/",
	"title": "1.7 Installation Kibana",
	"tags": [],
	"description": "Elasticsearch 의 시각화 플러그인 Kibana 설치하기",
	"content": " 1.7 Installation Kibana  Kibana 는 Elasticsearch 의 오픈 소스 데이터 시각화 플러그인이다. Elasticsearch 클러스터에 인덱싱 된 데이터들을 시각화 하는 기능을 제공한다.  yum 으로 Kibana 설치하기 1. RPM Repository 등록 vi /etc/yum.repos.d/kibana.repo\n[kibana-6.x] name=Kibana repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md  2. yum 명령어로 install yum install kibana Kibana 설정 Kibana 서버는 시작할 때 kibana.yml 에서 속성을 읽는다. kibana.yml 은 배포파일(.zip/.tar.gz) 로 설치한 경우 $KIBANA_HOME/config 에 위치하며 패키지 배포판 에서는 /etc/kibana 에 위치한다. kibana 서버는 기본적으로 localhost:5601 로 구동된다.\n1. kibana.yml 설정 vi /etc/kibana/kibana.yml\n server.host : 기본값 localhost. Back-end 서버의 host 를 지정한다. elasticsearch.url : ES 의 인스턴스 URL kibana.index : 저장된 검색, 시각화 및 대시보드를 저장하기 위에 ES 의 색인을 사용하는데, 인덱스가 아직 없을 경우 키바나가 새 인덱스를 생성  server.host: \u0026#34;localhost\u0026#34; elasticsearch.url: “http://localhost:9200\u0026#34; kibana.index: \u0026#34;.my-kibana\u0026#34; Kibana 서비스 시작하기 service kibana start "
},
{
	"uri": "/spring5.0/6/page-6-7/",
	"title": "6.7 국제화",
	"tags": [],
	"description": "스프링 어플리케이션 서비스에 국제화 기능을 추가한다.",
	"content": " 6.7 국제화 1. 국제화 국제화는 다양한 언어 및 문화권에 에서 사용할 수 있는 컨텐츠를 제공할 수 있도록 어플리케이션을 작성하는 것을 의미한다. 국제화(internationalization) 를 I18N이나 i18n으로, 현지화(localization)를 L10N이나 l10n 등으로 표기하기도 한다. 스프링 부트는 국제화를 위한 지원 기능을 내장하고 있다.\n2. 스프링부트프로젝트에서 국제화 지원설정하기 1.1 Application.java 에 LocaleResolver 추가 @Bean public SessionLocaleResolver localResolver() { SessionLocaleResolver sessionLocaleResolver = new SessionLocaleResolver(); sessionLocaleResolver.setDefaultLocale(Locale.US); return sessionLocaleResolver; } @Bean public ResourceBundleMessageSource messageSource (){ ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); messageSource.setBasename(\u0026#34;i18n/message\u0026#34;); messageSource.setUseCodeAsDefaultMessage(true); return messageSource; }  sessionLocaleResolver.setDefaultLocale(Locale.US) : 기본 로케일을 Locale.US 로 설정한다.\n messageSource.setBasename(\u0026quot;i18n/messages\u0026quot;) : 메세지 소스의 기본이름을 message 로 설정한다. 예를들어 message_kr.properties 지정할 수 있으며, message_kr.properties 를 사용할 수 없으면 message.properties 에서 검색된다.\n messageSource.setUseCodeAsDefaultMessage(true) : 메세지를 찾을 수 없는 경우 코드는 기본 메세지를 반환한다.\n  1.2 국제화 메세지 파일 생성하기 # message.properties welcome.message=Welcome in English # message_fr.properties welcome.message=Welcome in French  "
},
{
	"uri": "/spring5.0/6/page-6-8/",
	"title": "6.8 캐싱",
	"tags": [],
	"description": "스프링 부트의 캐싱 처리에 대해 정리",
	"content": " 6.8 캐싱 캐싱  캐싱은 많은 시간이나 연산이 필요한 일데 대한 결과를 저장해 두는 것 이라고 할 수 있다. 서비스의 데이터 캐싱은 어플리케이션의 성능과 확장성을 향상시키는데 중요한 역할을 한다. 스프링은 어노테이션에 기반을 둔 캐싱 추상화를 제공한다. JSR-107(JCahce) 구현체 들은 모두 지원한다. EhCache, Hazelcast, Infinispan, Couchbase, Redis 등이 기본적으로 자동설정에 포함되어 있다.  스프링 부트 프로젝트에 캐싱 적용하기 1. 의존성 추가 spring-boot-starter-cache 를 pom.xml 또는 build.gradle 에 추가한다. 이 의존모듈을 추가하면 JSR-107 및 스프링 캐싱 어노테이션을 사용하는데 필요한 의존성이 생긴다.\npom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-cache\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; build.gradle implementation(\u0026#39;org.springframework.boot:spring-boot-starter-cache\u0026#39;) 2. 캐싱 활성화 @EnableCaching @SpringBootApplication public class Chapter06Application {  @EnableCaching : 어플리케이션에서 캐싱을 가능하게 설정한다.  3. 데이터 캐싱하기 @Cacheable(\u0026#34;todos\u0026#34;) public List\u0026lt;Todo\u0026gt; retrieveTodos(String user) { List\u0026lt;Todo\u0026gt; filteredTodos = new ArrayList\u0026lt;Todo\u0026gt;(); for (Todo todo : todos) { if (todo.getUser().equals(user)) { filteredTodos.add(todo); } } return filteredTodos; } @Cacheable(cacheNames = \u0026#34;todos\u0026#34;, condition = \u0026#34;#user.length \u0026lt; 10\u0026#34;) public Todo retrieveTodo(int id) { for (Todo todo : todos) { if (todo.getId() == id) { return todo; } } return null; }  @CachePut : 데이터를 캐시에 명시적으로 추가하는데 사용된다. @CacheEvict : 캐시에서 오래된 데이터를 제거하는데 사용된다. @Caching : 여러 개의 중첩된 @Cacheable, @Cacheput, @CacheEvict 어노테이션을 동일한 메서드에서 사용할 수 있다.  JSR-107 캐싱 어노테이션  JSR-107 의 목표는 캐싱 어노테이션을 표준화 하는것. 스프링 캐싱 어노테이션과 JSR-107 이 제공하는 기능은 유사하다. 동일한 프로젝트에서 둘다 사용해서는 안된다.  주요 JSR-107 어노테이션  @CacheResult : @Cacheable 과 유사하다. @CacheRemove : @CacheEvit 와 유사하다. @CacheRemove 는 예외가 발생한 경우 조건부 제거를 지원한다. @CacheRemoveAll : @CacheEvict 와 유사 (allEntries = true) 캐시에서 모든 항목을 제거하는데 사용된다.  "
},
{
	"uri": "/elasticsearch/2/page-2-1/",
	"title": "2.1 Elasticsearch 기본 동작",
	"tags": [],
	"description": "Elasticsearch 의 기본동작 - 인덱스 생성, 삭제, 조회 하기",
	"content": " 2.1 Elasticsearch 기본 동작 1. Index 생성하기 인덱스를 생성하는 방법  Index Settings 를 정의한다. Index Mappings 를 정의한다. 사용자 정의된 도큐먼트를 인덱싱한다.  Index Settings Static Index Settings  index.number_of_shards : 인덱스가 가져야 하는 Primary 샤드의 개수 설정. (기본값 5)  Dynamic Index Settings  index.number_of_replicas : 각 기본 샤드의 복제본 (Replica 샤드 개수 설정). 기본값은 1 index.refresh_interval : 검색 commit point 를 만드는 refresh interval 설정 (새로 고침 작업수행 빈도). -1 비활성화. 기본값 1s index.routing.allocation.enable : 인덱스의 샤드들의 라우팅 허용 설정  Other Settings Analysis, Mapping, Slowlog \u0026hellip;\n인덱스 Settings 로 인덱싱 하기 PUT Method 를 사용 curl -X PUT \u0026#34;localhost:9200/twitter\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d { \u0026#34;settings\u0026#34; : { \u0026#34;index\u0026#34; : { \u0026#34;number_of_shards\u0026#34; : 3, \u0026#34;number_of_replicas\u0026#34; : 2 } } } CLI 사용 curl -X PUT -H \u0026#34;Content-Type:application/json\u0026#34; -d \u0026#39;{\u0026#34;settings\u0026#34; : {\u0026#34;index\u0026#34; : {\u0026#34;number_of_shards\u0026#34; : 3,\u0026#34;number_of_replicas\u0026#34; : 1}}}\u0026#39; http://localhost:9200/twitter2 Index 삭제하기 인덱스 삭제시에는 조심해서 삭제해야 한다. 주로 nginx 와 같은 웹서버를 앞단에 두어 특정 IP 에서만 DELETE Method 를 요청할 수 있도록 설정하거나 혹은 Index 의 Read only 설정을 사용하여 아예 삭제 할 수 없도록 설정한다.\n[참고]\n Elasticsearch Reference - index modules  "
},
{
	"uri": "/elasticsearch/2/page-2-2/",
	"title": "2.2 Plugin Installation",
	"tags": [],
	"description": "플러그인 설치",
	"content": " 2.2 Plugin Installation 플러그인 설치 인터넷이 가능한 환경에서 설치시 $ cd /usr/share/elasticsearch/ $ sudo bin/elasticsearch-plugin install [플러그인이름] # example $ sudo bin/elasticsearch-plugin install analysis-nori 파일서버 등에서 설치시 $ sudo bin/elasticsearch-plugin install file://path/to/plugin.zip # 파일서버 $ sudo bin/elasticsearch-plugin install [파일서버URL] 설치된 플러그인 리스트 확인 sudo bin/elasticsearch-plugin list 설치된 플러그인 제거 sudo bin/elasticsearch-plugin remove [플러그인이름] [참고]\n Elasticsearch Reference - plugin-management  "
},
{
	"uri": "/elasticsearch/2/page-2-3/",
	"title": "2.3 Head",
	"tags": [],
	"description": "Elasticsearch Head 소개",
	"content": " 2.3 Elasticsarch Head Elasticsearch Head 클러스트들을 한눈에 보기 위한 도구. 직접 서버를 구성하여 설치할 수도 있고 크롬의 브라우저 익스텐션으로도 제공한다.\nInstallation ES Head git repository 에서 클론 혹은 다운로드한다. sudo yum -y install git # # git 이 설치되어 있지 않으면 git clone https://github.com/mobz/elasticsearch-head.git npm 으로 관련 의존성 모듈 설치 cd elasticsearch-head/ sudo yum -y install bzip2 epel-release sudo yum -y install npm # Node 가 설치되어있어야 한다. npm install 내장서버 실행 npm run start 브라우저에서 http://localhost:9100 으로 확인한다. [참고]\n Head Git Repository  "
},
{
	"uri": "/elasticsearch/2/page-2-4/",
	"title": "2.5 Elastic-HQ",
	"tags": [],
	"description": "",
	"content": " 2.5 Elastic HQ Elastic HQ 설치하기 Requirements  Python 3.4+ Elasticsearch. Supported versions: 2.x, 5.x, 6.x  설치과정 ElasticHQ Git Repository 에서 클론 혹은 다운로드 한다. sudo yum -y install git # git 이 설치되어 있지 않으면 git clone https://github.com/ElasticHQ/elasticsearch-HQ.git Python 3.4+ 설치한다. (pip 은 파이선 패키지 관리자) cd elasticsearch-HQ/ # clone 한 디렉터리로 이동 후 sudo yum -y install python34 python34-pip Repository 의 의존성 패키지 설치한다. pip install -r requirements.txt 서버시작 구동 python3 application.py 브라우저에서 http://localhost:5000 로 접속한다. [참고]\n HQ Git Repository HQ Documents  "
},
{
	"uri": "/elasticsearch/2/page-2-5/",
	"title": "2.5 Elasticsearch Plugins",
	"tags": [],
	"description": "",
	"content": " 2.5 Elasticsearch Plugins Elasticsearch 플러그인  플러그인은 사용자 정의 방식에 의해 ES 의 긴능을 향상 시키는 방법이다. 플러그인은 모든 노드에 설치해야 하며 설치 후 클러스터를 재시작 해야 한다.  플러그인 범주 Core Plugins (권고)  Elasticsearch 에서 공식적으로 지원하는 플러그인 Elasticsearch 버전이 업데이트 될때마다 버전 업데이트가 지원됨.  Community contributed  개인 개발자나 회사에 의해 지원되는 플러그인  [참고]\n Elasticsearch Reference - modules-plugins.  "
},
{
	"uri": "/programming/",
	"title": "Programming",
	"tags": [],
	"description": "",
	"content": " Programming  프로그래밍 언어별로 정리하기  "
},
{
	"uri": "/python/",
	"title": "python",
	"tags": [],
	"description": "",
	"content": " Python 시작하기 pyenv?  pyenv 는 하나의 시스템에서 여러 다양한 버전의 Python 을 관리하기 위한 관리 도구이다. 파이썬 버전을 사용자 단위 혹은 프로젝트별로 각각 다른 버전을 사용할 수 있다. ruby 의 rvm, Node.js 의 nvm 와 같은 역할을 하는 Version Manager 이다. https://github.com/pyenv/pyenv  pyenv 설치 1. python 을 설치하는데 필요한 패키지 설치 $ sudo apt install curl git-core gcc make zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev libssl-dev 2. pyenv 소스 다운로드 Gibhub 저장소에서 최신 pyenv 소스를 클론하여 ~/.pyenv 경로에 설치한다.\n$ git clone https://github.com/pyenv/pyenv.git ~/.pyenv 3. 환경변수 등록  사용하는 Shell 맞추어 환경변수 설정한다. bash shell 을 사용하는 경우 ~/.bash_profile 또는 ~/.bashrc  $ echo \u0026#39;export PYENV_ROOT=\u0026#34;$HOME/.pyenv\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc $ echo \u0026#39;export PATH=\u0026#34;$PYENV_ROOT/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc $ echo -e \u0026#39;if command -v pyenv 1\u0026gt;/dev/null 2\u0026gt;\u0026amp;1; then\\n eval \u0026#34;$(pyenv init -)\u0026#34;\\nfi\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # 변경 사항 적용을 위한 Shell 재기동 $ exec \u0026#34;$SHELL\u0026#34; pyenv 사용하기 1. pyenv 설치 가능한 버전 확인  python 버전을 설치하기 전에 이 명령으로 설치 가능한 버전을 확인 할 수 있다.  $ pyenv install --list # 설치가능한 python 버전을 보여준다. Available versions: 2.1.3 2.2.3 2.3.7 2.4.0 2.4.1 2.4.2 2. install 명령어를 사용하여 원하는 버전을 설치한다. $ pyenv install 3.7.2 Downloading Python-3.7.2.tar.xz... -\u0026gt; https://www.python.org/ftp/python/3.7.2/Python-3.7.2.tar.xz Installing Python-3.7.2... 3. 설치된 모든 python 버전 보기 $ pyenv versions # 설치된 파이썬 버전이 출력 pyenv versions system 3.7.0 * anaconda3-5.3.1 (set by /home/riley/.pyenv/version 4. pyenv 명령어를 사용하여 전역 파이썬 버전 설정하기 $ pyenv global 3.7.0 $ python -V # 변경된 버전 출력 $ Python 3.7.0 [오류사항 참고]\n1. 빌드 설치시 ModuleNotFoundError: No module named _ctypes 로 파이썬 빌드가 안될때  libffi-dev 를 설치한다. https://stackoverflow.com/a/35460842  # libffi-dev $ apt-get install -y libffi-dev [참고 및 출처]\n 리눅스에서 파이썬 설치 및 파이썬 버전관리하기  "
},
{
	"uri": "/python/page-1-1/",
	"title": "파이썬의 자료형",
	"tags": [],
	"description": "",
	"content": " 파이썬의 자료형 파이썬의 변수와 객체  C 와 같은 언어에서 변수는 메모리 상 저장공간에 직접 값을 할당한다면, 파이썬에서 변수는 메모리상에 생성된 객체를 참조 하는 개념이다.  \u0026gt;\u0026gt;\u0026gt; x = 100 \u0026gt;\u0026gt;\u0026gt; y = 100 \u0026gt;\u0026gt;\u0026gt; x is y True # 257 부터는 서로 다른 객체로 생성됨. \u0026gt;\u0026gt;\u0026gt; x = 257 \u0026gt;\u0026gt;\u0026gt; y = 257 \u0026gt;\u0026gt;\u0026gt; x is y False 위의 예제에서는 x 와 y 는 100 이라는 메모리상 같은 객체를 가리키고 있다.(= 같은 메모리 주소를 가리킨다.) 파이썬에서는 자주 사용하는 정수 범위(0-256) 는 메모리에 한 번만 올려두고 여러 변수가 가리키게 함으로써 메모리를 효과적으로 사용하고 있다.\n자바에서 기본타입(Primitive Type) 을 wrapper class 를 사용하여 객체로 다루는 것과 비슷하게 동작한다. (하지만 자바의 경우는 100 이라는 값을 갖는 새로운 메모리 주소를 생성할 수 있다.)\n파이썬의 숫자 자료형  파이썬에서는 숫자를 정수(int), 실수(float), 복소수(complex) 로 구분한다.  1. 정수형 (Integer)  정수를 표현하는 자료형으로 10 진수 이외에도 2진수, 8진수, 16진수 로도 표현 할 수 있다.  \u0026gt;\u0026gt;\u0026gt; a = 0o177 # 8진수 (Oo 또는 0O 시작) \u0026gt;\u0026gt;\u0026gt; b = 0x8ff # 16진수 (Ox 시작)  파이썬에서는 정수 자료형에 오버플로우 가 없다  2. 실수형 (Floating-point)  파이썬에서 실수형은 소수점이 포함된 숫자를 의미한다. 정수부가 0 인 소수는 0 을 생략 할 수 있다.  \u0026gt;\u0026gt;\u0026gt; .1 0.1  컴퓨터에서는 표준에 따라 부동소수점 방식으로 표현한다. (IEEE 부동 소수점방식) 부동소수점 방식에는 숫자를 정수로 된 유효숫자와 정수로 된 지수의 곱으로 표현한다.  \u0026gt;\u0026gt;\u0026gt; 123e2 # 123.0 x 100 = 12300.0 12300.0  컴퓨터에서 부동 소수점에 의한 실수 표현은 오차가 존재한다.\n 3. 복소수 (complex)  파이썬에서는 허수를 표시하려면 i 가 아닌 j 를 사용한다.  \u0026gt;\u0026gt;\u0026gt; a = 3 + 3j \u0026gt;\u0026gt;\u0026gt; type(a) \u0026lt;class \u0026#39;complex\u0026#39;\u0026gt;\u0026gt;\u0026gt;\u0026gt; a = complex(3, 3)\u0026gt;\u0026gt;\u0026gt; a(3+3j) 연산자  파이썬에서 사용하는 연산자     연산자 설명     + 덧셈   - 뺄셈   * 곱셈   / 나눗셈   // 나눗셈의 몫   % 나누셈의 나머지   ** 지수 연산자   +value 단항덧셈   -value 단항뺄셈    \u0026gt;\u0026gt;\u0026gt; 2 + 2 4 \u0026gt;\u0026gt;\u0026gt; 50 - 5 * 6 20 \u0026gt;\u0026gt;\u0026gt; (50 - 5*6) / 4 5.0 \u0026gt;\u0026gt;\u0026gt; 8 / 5 1.6 \u0026gt;\u0026gt;\u0026gt;   / 연산자의 경우 python2 에서는 항목에 따라 정수형으로 나누어 떨어지지 않을경우 소수점을 버림으로써 정수형을 유지하는 반면, python3 에서는 정수형으로 나누어 떨어지지 않을경우 자동으로 소수형으로 형 변환된 결과를 출력한다.  Python 2.7.15 (default, Mar 14 2019, 22:47:06) [GCC 7.3.0] on linux2 Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; 8 / 5 1 Python 3.7.0 (default, Mar 13 2019, 22:44:23) [GCC 7.3.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; 8 / 5 1.6  / 의 연산자는 항상 float 를 리턴함으로 정수형 결과를 리턴받고 싶다면 // 연산자를 이용하면 된다.  인터프리터 환경에서 _ 활용  파이썬 인터프리터에서는 마지막으로 실행된 결과값이 _ 라는 변수에 저장된다.  \u0026gt;\u0026gt;\u0026gt; tax = 12.5 / 100 \u0026gt;\u0026gt;\u0026gt; price = 100.50 \u0026gt;\u0026gt;\u0026gt; price * tax 12.5625 \u0026gt;\u0026gt;\u0026gt; price + _ 113.0625 \u0026gt;\u0026gt;\u0026gt; round(_, 2) 113.06 문자열  파이썬의 문자열 표현식 : ''(Single quotes) 또는 \u0026quot;\u0026quot; (double quotes) 이스케이프 (\\) 를 사용하여 문자열 리터럴 내에 이스케이프 혹은 연속된 3개 이상의 따옴표 표현 할 수 있다.  \u0026gt;\u0026gt;\u0026gt; \u0026#39;spam eggs\u0026#39; # single quotes \u0026#39;spam eggs\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;doesn\\\u0026#39;t\u0026#39; # use \\\u0026#39; to escape the single quote... \u0026#34;doesn\u0026#39;t\u0026#34; \u0026gt;\u0026gt;\u0026gt; \u0026#34;doesn\u0026#39;t\u0026#34; # ...or use double quotes instead \u0026#34;doesn\u0026#39;t\u0026#34;  문자열은 + 로 연결할 수 있고 * 연산자로 반복시킬 수 있다. 두 개이상의 문자열 리터럴이 연속으로 나타나면 자동으로 이어 붙여준다. 변수들 끼리 혹은 변수와 리터럴을 이어 붙이려면 + 연산자를 사용해야 한다.  \u0026gt;\u0026gt;\u0026gt; 3 * \u0026#39;un\u0026#39; + \u0026#39;ium\u0026#39; \u0026#39;unununium\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;Py\u0026#39;\u0026#39;thon\u0026#39; \u0026#39;Python\u0026#39; # 변수와 리터럴을 이어 붙이려면 + 사용 \u0026gt;\u0026gt; prefix = \u0026#39;Py\u0026#39; \u0026gt;\u0026gt;\u0026gt; prefix + \u0026#39;thon\u0026#39; \u0026#39;Python\u0026#39;"
},
{
	"uri": "/",
	"title": "@stoptheworld99",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]